// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.confluentcloud;

import com.pulumi.confluentcloud.Utilities;
import com.pulumi.confluentcloud.inputs.GetAccessPointArgs;
import com.pulumi.confluentcloud.inputs.GetAccessPointPlainArgs;
import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingPlainArgs;
import com.pulumi.confluentcloud.inputs.GetBusinessMetadataPlainArgs;
import com.pulumi.confluentcloud.inputs.GetByokKeyArgs;
import com.pulumi.confluentcloud.inputs.GetByokKeyPlainArgs;
import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationPlainArgs;
import com.pulumi.confluentcloud.inputs.GetCertificateAuthorityArgs;
import com.pulumi.confluentcloud.inputs.GetCertificateAuthorityPlainArgs;
import com.pulumi.confluentcloud.inputs.GetCertificatePoolArgs;
import com.pulumi.confluentcloud.inputs.GetCertificatePoolPlainArgs;
import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
import com.pulumi.confluentcloud.inputs.GetClusterLinkPlainArgs;
import com.pulumi.confluentcloud.inputs.GetConnectArtifactArgs;
import com.pulumi.confluentcloud.inputs.GetConnectArtifactPlainArgs;
import com.pulumi.confluentcloud.inputs.GetDnsRecordArgs;
import com.pulumi.confluentcloud.inputs.GetDnsRecordPlainArgs;
import com.pulumi.confluentcloud.inputs.GetEnvironmentArgs;
import com.pulumi.confluentcloud.inputs.GetEnvironmentPlainArgs;
import com.pulumi.confluentcloud.inputs.GetFlinkArtifactArgs;
import com.pulumi.confluentcloud.inputs.GetFlinkArtifactPlainArgs;
import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolArgs;
import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolPlainArgs;
import com.pulumi.confluentcloud.inputs.GetFlinkConnectionArgs;
import com.pulumi.confluentcloud.inputs.GetFlinkConnectionPlainArgs;
import com.pulumi.confluentcloud.inputs.GetFlinkRegionArgs;
import com.pulumi.confluentcloud.inputs.GetFlinkRegionPlainArgs;
import com.pulumi.confluentcloud.inputs.GetGatewayArgs;
import com.pulumi.confluentcloud.inputs.GetGatewayPlainArgs;
import com.pulumi.confluentcloud.inputs.GetGroupMappingArgs;
import com.pulumi.confluentcloud.inputs.GetGroupMappingPlainArgs;
import com.pulumi.confluentcloud.inputs.GetIdentityPoolArgs;
import com.pulumi.confluentcloud.inputs.GetIdentityPoolPlainArgs;
import com.pulumi.confluentcloud.inputs.GetIdentityProviderArgs;
import com.pulumi.confluentcloud.inputs.GetIdentityProviderPlainArgs;
import com.pulumi.confluentcloud.inputs.GetInvitationArgs;
import com.pulumi.confluentcloud.inputs.GetInvitationPlainArgs;
import com.pulumi.confluentcloud.inputs.GetIpAddressesArgs;
import com.pulumi.confluentcloud.inputs.GetIpAddressesPlainArgs;
import com.pulumi.confluentcloud.inputs.GetIpFilterArgs;
import com.pulumi.confluentcloud.inputs.GetIpFilterPlainArgs;
import com.pulumi.confluentcloud.inputs.GetIpGroupArgs;
import com.pulumi.confluentcloud.inputs.GetIpGroupPlainArgs;
import com.pulumi.confluentcloud.inputs.GetKafkaClientQuotaArgs;
import com.pulumi.confluentcloud.inputs.GetKafkaClientQuotaPlainArgs;
import com.pulumi.confluentcloud.inputs.GetKafkaClusterArgs;
import com.pulumi.confluentcloud.inputs.GetKafkaClusterPlainArgs;
import com.pulumi.confluentcloud.inputs.GetKafkaClustersArgs;
import com.pulumi.confluentcloud.inputs.GetKafkaClustersPlainArgs;
import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
import com.pulumi.confluentcloud.inputs.GetKafkaTopicPlainArgs;
import com.pulumi.confluentcloud.inputs.GetKsqlClusterArgs;
import com.pulumi.confluentcloud.inputs.GetKsqlClusterPlainArgs;
import com.pulumi.confluentcloud.inputs.GetNetworkArgs;
import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointArgs;
import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointPlainArgs;
import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceArgs;
import com.pulumi.confluentcloud.inputs.GetNetworkLinkServicePlainArgs;
import com.pulumi.confluentcloud.inputs.GetNetworkPlainArgs;
import com.pulumi.confluentcloud.inputs.GetPeeringArgs;
import com.pulumi.confluentcloud.inputs.GetPeeringPlainArgs;
import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessArgs;
import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessPlainArgs;
import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentArgs;
import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionArgs;
import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionPlainArgs;
import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentPlainArgs;
import com.pulumi.confluentcloud.inputs.GetProviderIntegrationArgs;
import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationArgs;
import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationPlainArgs;
import com.pulumi.confluentcloud.inputs.GetProviderIntegrationPlainArgs;
import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupPlainArgs;
import com.pulumi.confluentcloud.inputs.GetRoleBindingArgs;
import com.pulumi.confluentcloud.inputs.GetRoleBindingPlainArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaPlainArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigPlainArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModePlainArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterPlainArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersPlainArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekPlainArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekPlainArgs;
import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
import com.pulumi.confluentcloud.inputs.GetSchemasPlainArgs;
import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
import com.pulumi.confluentcloud.inputs.GetServiceAccountPlainArgs;
import com.pulumi.confluentcloud.inputs.GetSubjectConfigArgs;
import com.pulumi.confluentcloud.inputs.GetSubjectConfigPlainArgs;
import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
import com.pulumi.confluentcloud.inputs.GetSubjectModePlainArgs;
import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
import com.pulumi.confluentcloud.inputs.GetTableflowTopicPlainArgs;
import com.pulumi.confluentcloud.inputs.GetTagArgs;
import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
import com.pulumi.confluentcloud.inputs.GetTagBindingPlainArgs;
import com.pulumi.confluentcloud.inputs.GetTagPlainArgs;
import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentArgs;
import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentPlainArgs;
import com.pulumi.confluentcloud.inputs.GetUserArgs;
import com.pulumi.confluentcloud.inputs.GetUserPlainArgs;
import com.pulumi.confluentcloud.outputs.GetAccessPointResult;
import com.pulumi.confluentcloud.outputs.GetBusinessMetadataBindingResult;
import com.pulumi.confluentcloud.outputs.GetBusinessMetadataResult;
import com.pulumi.confluentcloud.outputs.GetByokKeyResult;
import com.pulumi.confluentcloud.outputs.GetCatalogIntegrationResult;
import com.pulumi.confluentcloud.outputs.GetCertificateAuthorityResult;
import com.pulumi.confluentcloud.outputs.GetCertificatePoolResult;
import com.pulumi.confluentcloud.outputs.GetClusterLinkResult;
import com.pulumi.confluentcloud.outputs.GetConnectArtifactResult;
import com.pulumi.confluentcloud.outputs.GetDnsRecordResult;
import com.pulumi.confluentcloud.outputs.GetEnvironmentResult;
import com.pulumi.confluentcloud.outputs.GetEnvironmentsResult;
import com.pulumi.confluentcloud.outputs.GetFlinkArtifactResult;
import com.pulumi.confluentcloud.outputs.GetFlinkComputePoolResult;
import com.pulumi.confluentcloud.outputs.GetFlinkConnectionResult;
import com.pulumi.confluentcloud.outputs.GetFlinkRegionResult;
import com.pulumi.confluentcloud.outputs.GetGatewayResult;
import com.pulumi.confluentcloud.outputs.GetGroupMappingResult;
import com.pulumi.confluentcloud.outputs.GetIdentityPoolResult;
import com.pulumi.confluentcloud.outputs.GetIdentityProviderResult;
import com.pulumi.confluentcloud.outputs.GetInvitationResult;
import com.pulumi.confluentcloud.outputs.GetIpAddressesResult;
import com.pulumi.confluentcloud.outputs.GetIpFilterResult;
import com.pulumi.confluentcloud.outputs.GetIpGroupResult;
import com.pulumi.confluentcloud.outputs.GetKafkaClientQuotaResult;
import com.pulumi.confluentcloud.outputs.GetKafkaClusterResult;
import com.pulumi.confluentcloud.outputs.GetKafkaClustersResult;
import com.pulumi.confluentcloud.outputs.GetKafkaTopicResult;
import com.pulumi.confluentcloud.outputs.GetKsqlClusterResult;
import com.pulumi.confluentcloud.outputs.GetNetworkLinkEndpointResult;
import com.pulumi.confluentcloud.outputs.GetNetworkLinkServiceResult;
import com.pulumi.confluentcloud.outputs.GetNetworkResult;
import com.pulumi.confluentcloud.outputs.GetOrganizationResult;
import com.pulumi.confluentcloud.outputs.GetPeeringResult;
import com.pulumi.confluentcloud.outputs.GetPrivateLinkAccessResult;
import com.pulumi.confluentcloud.outputs.GetPrivateLinkAttachmentConnectionResult;
import com.pulumi.confluentcloud.outputs.GetPrivateLinkAttachmentResult;
import com.pulumi.confluentcloud.outputs.GetProviderIntegrationAuthorizationResult;
import com.pulumi.confluentcloud.outputs.GetProviderIntegrationResult;
import com.pulumi.confluentcloud.outputs.GetProviderIntegrationSetupResult;
import com.pulumi.confluentcloud.outputs.GetRoleBindingResult;
import com.pulumi.confluentcloud.outputs.GetSchemaRegistryClusterConfigResult;
import com.pulumi.confluentcloud.outputs.GetSchemaRegistryClusterModeResult;
import com.pulumi.confluentcloud.outputs.GetSchemaRegistryClusterResult;
import com.pulumi.confluentcloud.outputs.GetSchemaRegistryClustersResult;
import com.pulumi.confluentcloud.outputs.GetSchemaRegistryDekResult;
import com.pulumi.confluentcloud.outputs.GetSchemaRegistryKekResult;
import com.pulumi.confluentcloud.outputs.GetSchemaResult;
import com.pulumi.confluentcloud.outputs.GetSchemasResult;
import com.pulumi.confluentcloud.outputs.GetServiceAccountResult;
import com.pulumi.confluentcloud.outputs.GetSubjectConfigResult;
import com.pulumi.confluentcloud.outputs.GetSubjectModeResult;
import com.pulumi.confluentcloud.outputs.GetTableflowTopicResult;
import com.pulumi.confluentcloud.outputs.GetTagBindingResult;
import com.pulumi.confluentcloud.outputs.GetTagResult;
import com.pulumi.confluentcloud.outputs.GetTransitGatewayAttachmentResult;
import com.pulumi.confluentcloud.outputs.GetUserResult;
import com.pulumi.confluentcloud.outputs.GetUsersResult;
import com.pulumi.core.Output;
import com.pulumi.core.TypeShape;
import com.pulumi.deployment.Deployment;
import com.pulumi.deployment.InvokeOptions;
import com.pulumi.deployment.InvokeOutputOptions;
import com.pulumi.resources.InvokeArgs;
import java.util.concurrent.CompletableFuture;

public final class ConfluentcloudFunctions {
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.AccessPoint` describes a Access Point data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointArgs;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getAccessPoint(GetAccessPointArgs.builder()
     *             .id("ap-abc123")
     *             .environment(GetAccessPointEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("accessPoint", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetAccessPointResult> getAccessPoint(GetAccessPointArgs args) {
        return getAccessPoint(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.AccessPoint` describes a Access Point data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointArgs;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getAccessPoint(GetAccessPointArgs.builder()
     *             .id("ap-abc123")
     *             .environment(GetAccessPointEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("accessPoint", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetAccessPointResult> getAccessPointPlain(GetAccessPointPlainArgs args) {
        return getAccessPointPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.AccessPoint` describes a Access Point data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointArgs;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getAccessPoint(GetAccessPointArgs.builder()
     *             .id("ap-abc123")
     *             .environment(GetAccessPointEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("accessPoint", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetAccessPointResult> getAccessPoint(GetAccessPointArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getAccessPoint:getAccessPoint", TypeShape.of(GetAccessPointResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.AccessPoint` describes a Access Point data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointArgs;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getAccessPoint(GetAccessPointArgs.builder()
     *             .id("ap-abc123")
     *             .environment(GetAccessPointEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("accessPoint", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetAccessPointResult> getAccessPoint(GetAccessPointArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getAccessPoint:getAccessPoint", TypeShape.of(GetAccessPointResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.AccessPoint` describes a Access Point data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointArgs;
     * import com.pulumi.confluentcloud.inputs.GetAccessPointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getAccessPoint(GetAccessPointArgs.builder()
     *             .id("ap-abc123")
     *             .environment(GetAccessPointEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("accessPoint", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetAccessPointResult> getAccessPointPlain(GetAccessPointPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getAccessPoint:getAccessPoint", TypeShape.of(GetAccessPointResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadata` describes a Business Metadata data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetBusinessMetadataResult> getBusinessMetadata(GetBusinessMetadataArgs args) {
        return getBusinessMetadata(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadata` describes a Business Metadata data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static CompletableFuture<GetBusinessMetadataResult> getBusinessMetadataPlain(GetBusinessMetadataPlainArgs args) {
        return getBusinessMetadataPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadata` describes a Business Metadata data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetBusinessMetadataResult> getBusinessMetadata(GetBusinessMetadataArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getBusinessMetadata:getBusinessMetadata", TypeShape.of(GetBusinessMetadataResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadata` describes a Business Metadata data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetBusinessMetadataResult> getBusinessMetadata(GetBusinessMetadataArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getBusinessMetadata:getBusinessMetadata", TypeShape.of(GetBusinessMetadataResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadata` describes a Business Metadata data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getBusinessMetadata(GetBusinessMetadataArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static CompletableFuture<GetBusinessMetadataResult> getBusinessMetadataPlain(GetBusinessMetadataPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getBusinessMetadata:getBusinessMetadata", TypeShape.of(GetBusinessMetadataResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadataBinding` describes a Business Metadata Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetBusinessMetadataBindingResult> getBusinessMetadataBinding(GetBusinessMetadataBindingArgs args) {
        return getBusinessMetadataBinding(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadataBinding` describes a Business Metadata Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static CompletableFuture<GetBusinessMetadataBindingResult> getBusinessMetadataBindingPlain(GetBusinessMetadataBindingPlainArgs args) {
        return getBusinessMetadataBindingPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadataBinding` describes a Business Metadata Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetBusinessMetadataBindingResult> getBusinessMetadataBinding(GetBusinessMetadataBindingArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getBusinessMetadataBinding:getBusinessMetadataBinding", TypeShape.of(GetBusinessMetadataBindingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadataBinding` describes a Business Metadata Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetBusinessMetadataBindingResult> getBusinessMetadataBinding(GetBusinessMetadataBindingArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getBusinessMetadataBinding:getBusinessMetadataBinding", TypeShape.of(GetBusinessMetadataBindingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.BusinessMetadataBinding` describes a Business Metadata Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .schemaRegistryCluster(GetBusinessMetadataBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetBusinessMetadataBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetBusinessMetadataBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getBusinessMetadataBinding(GetBusinessMetadataBindingArgs.builder()
     *             .businessMetadataName(pii.name())
     *             .entityName(String.format("%s:%s:%s", schemaRegistryId,kafkaId,mainConfluentKafkaTopic.topicName()))
     *             .entityType("kafka_topic")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static CompletableFuture<GetBusinessMetadataBindingResult> getBusinessMetadataBindingPlain(GetBusinessMetadataBindingPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getBusinessMetadataBinding:getBusinessMetadataBinding", TypeShape.of(GetBusinessMetadataBindingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ByokKey` describes a BYOK Key data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetByokKeyArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azureKey = ConfluentcloudFunctions.getByokKey(GetByokKeyArgs.builder()
     *             .id("cck-abcde")
     *             .build());
     * 
     *         ctx.export("byok", azureKey);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetByokKeyResult> getByokKey(GetByokKeyArgs args) {
        return getByokKey(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ByokKey` describes a BYOK Key data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetByokKeyArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azureKey = ConfluentcloudFunctions.getByokKey(GetByokKeyArgs.builder()
     *             .id("cck-abcde")
     *             .build());
     * 
     *         ctx.export("byok", azureKey);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetByokKeyResult> getByokKeyPlain(GetByokKeyPlainArgs args) {
        return getByokKeyPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ByokKey` describes a BYOK Key data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetByokKeyArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azureKey = ConfluentcloudFunctions.getByokKey(GetByokKeyArgs.builder()
     *             .id("cck-abcde")
     *             .build());
     * 
     *         ctx.export("byok", azureKey);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetByokKeyResult> getByokKey(GetByokKeyArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getByokKey:getByokKey", TypeShape.of(GetByokKeyResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ByokKey` describes a BYOK Key data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetByokKeyArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azureKey = ConfluentcloudFunctions.getByokKey(GetByokKeyArgs.builder()
     *             .id("cck-abcde")
     *             .build());
     * 
     *         ctx.export("byok", azureKey);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetByokKeyResult> getByokKey(GetByokKeyArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getByokKey:getByokKey", TypeShape.of(GetByokKeyResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ByokKey` describes a BYOK Key data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetByokKeyArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azureKey = ConfluentcloudFunctions.getByokKey(GetByokKeyArgs.builder()
     *             .id("cck-abcde")
     *             .build());
     * 
     *         ctx.export("byok", azureKey);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetByokKeyResult> getByokKeyPlain(GetByokKeyPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getByokKey:getByokKey", TypeShape.of(GetByokKeyResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CatalogIntegration` describes a Catalog Integration data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Catalog Integrations in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .environment(GetCatalogIntegrationEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetCatalogIntegrationKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .id("tci-abc123")
     *             .credentials(GetCatalogIntegrationCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Catalog Integration in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .id("tci-abc123")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetCatalogIntegrationResult> getCatalogIntegration(GetCatalogIntegrationArgs args) {
        return getCatalogIntegration(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CatalogIntegration` describes a Catalog Integration data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Catalog Integrations in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .environment(GetCatalogIntegrationEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetCatalogIntegrationKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .id("tci-abc123")
     *             .credentials(GetCatalogIntegrationCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Catalog Integration in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .id("tci-abc123")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetCatalogIntegrationResult> getCatalogIntegrationPlain(GetCatalogIntegrationPlainArgs args) {
        return getCatalogIntegrationPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CatalogIntegration` describes a Catalog Integration data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Catalog Integrations in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .environment(GetCatalogIntegrationEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetCatalogIntegrationKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .id("tci-abc123")
     *             .credentials(GetCatalogIntegrationCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Catalog Integration in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .id("tci-abc123")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetCatalogIntegrationResult> getCatalogIntegration(GetCatalogIntegrationArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getCatalogIntegration:getCatalogIntegration", TypeShape.of(GetCatalogIntegrationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CatalogIntegration` describes a Catalog Integration data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Catalog Integrations in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .environment(GetCatalogIntegrationEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetCatalogIntegrationKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .id("tci-abc123")
     *             .credentials(GetCatalogIntegrationCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Catalog Integration in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .id("tci-abc123")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetCatalogIntegrationResult> getCatalogIntegration(GetCatalogIntegrationArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getCatalogIntegration:getCatalogIntegration", TypeShape.of(GetCatalogIntegrationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CatalogIntegration` describes a Catalog Integration data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Catalog Integrations in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .environment(GetCatalogIntegrationEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetCatalogIntegrationKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .id("tci-abc123")
     *             .credentials(GetCatalogIntegrationCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Catalog Integration in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCatalogIntegrationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getCatalogIntegration(GetCatalogIntegrationArgs.builder()
     *             .id("tci-abc123")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetCatalogIntegrationResult> getCatalogIntegrationPlain(GetCatalogIntegrationPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getCatalogIntegration:getCatalogIntegration", TypeShape.of(GetCatalogIntegrationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificateAuthority` describes a Certificate Authority data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificateAuthority(GetCertificateAuthorityArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("certificateAuthority", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetCertificateAuthorityResult> getCertificateAuthority(GetCertificateAuthorityArgs args) {
        return getCertificateAuthority(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificateAuthority` describes a Certificate Authority data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificateAuthority(GetCertificateAuthorityArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("certificateAuthority", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetCertificateAuthorityResult> getCertificateAuthorityPlain(GetCertificateAuthorityPlainArgs args) {
        return getCertificateAuthorityPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificateAuthority` describes a Certificate Authority data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificateAuthority(GetCertificateAuthorityArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("certificateAuthority", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetCertificateAuthorityResult> getCertificateAuthority(GetCertificateAuthorityArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getCertificateAuthority:getCertificateAuthority", TypeShape.of(GetCertificateAuthorityResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificateAuthority` describes a Certificate Authority data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificateAuthority(GetCertificateAuthorityArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("certificateAuthority", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetCertificateAuthorityResult> getCertificateAuthority(GetCertificateAuthorityArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getCertificateAuthority:getCertificateAuthority", TypeShape.of(GetCertificateAuthorityResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificateAuthority` describes a Certificate Authority data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificateAuthority(GetCertificateAuthorityArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("certificateAuthority", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetCertificateAuthorityResult> getCertificateAuthorityPlain(GetCertificateAuthorityPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getCertificateAuthority:getCertificateAuthority", TypeShape.of(GetCertificateAuthorityResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificatePool` describes a Certificate Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificatePool(GetCertificatePoolArgs.builder()
     *             .id("pool-def456")
     *             .certificateAuthority(GetCertificatePoolCertificateAuthorityArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("certificatePool", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetCertificatePoolResult> getCertificatePool(GetCertificatePoolArgs args) {
        return getCertificatePool(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificatePool` describes a Certificate Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificatePool(GetCertificatePoolArgs.builder()
     *             .id("pool-def456")
     *             .certificateAuthority(GetCertificatePoolCertificateAuthorityArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("certificatePool", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetCertificatePoolResult> getCertificatePoolPlain(GetCertificatePoolPlainArgs args) {
        return getCertificatePoolPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificatePool` describes a Certificate Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificatePool(GetCertificatePoolArgs.builder()
     *             .id("pool-def456")
     *             .certificateAuthority(GetCertificatePoolCertificateAuthorityArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("certificatePool", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetCertificatePoolResult> getCertificatePool(GetCertificatePoolArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getCertificatePool:getCertificatePool", TypeShape.of(GetCertificatePoolResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificatePool` describes a Certificate Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificatePool(GetCertificatePoolArgs.builder()
     *             .id("pool-def456")
     *             .certificateAuthority(GetCertificatePoolCertificateAuthorityArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("certificatePool", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetCertificatePoolResult> getCertificatePool(GetCertificatePoolArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getCertificatePool:getCertificatePool", TypeShape.of(GetCertificatePoolResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.CertificatePool` describes a Certificate Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetCertificatePoolCertificateAuthorityArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getCertificatePool(GetCertificatePoolArgs.builder()
     *             .id("pool-def456")
     *             .certificateAuthority(GetCertificatePoolCertificateAuthorityArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("certificatePool", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetCertificatePoolResult> getCertificatePoolPlain(GetCertificatePoolPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getCertificatePool:getCertificatePool", TypeShape.of(GetCertificatePoolResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ClusterLink` describes a Cluster Link data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .credentials(GetClusterLinkCredentialsArgs.builder()
     *                 .key(app_manager_west_cluster_api_key.id())
     *                 .secret(app_manager_west_cluster_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #3: Manage Kafka cluster(s) in the same Pulumi Stack using OAuth authentication
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetClusterLinkResult> getClusterLink(GetClusterLinkArgs args) {
        return getClusterLink(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ClusterLink` describes a Cluster Link data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .credentials(GetClusterLinkCredentialsArgs.builder()
     *                 .key(app_manager_west_cluster_api_key.id())
     *                 .secret(app_manager_west_cluster_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #3: Manage Kafka cluster(s) in the same Pulumi Stack using OAuth authentication
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetClusterLinkResult> getClusterLinkPlain(GetClusterLinkPlainArgs args) {
        return getClusterLinkPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ClusterLink` describes a Cluster Link data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .credentials(GetClusterLinkCredentialsArgs.builder()
     *                 .key(app_manager_west_cluster_api_key.id())
     *                 .secret(app_manager_west_cluster_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #3: Manage Kafka cluster(s) in the same Pulumi Stack using OAuth authentication
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetClusterLinkResult> getClusterLink(GetClusterLinkArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getClusterLink:getClusterLink", TypeShape.of(GetClusterLinkResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ClusterLink` describes a Cluster Link data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .credentials(GetClusterLinkCredentialsArgs.builder()
     *                 .key(app_manager_west_cluster_api_key.id())
     *                 .secret(app_manager_west_cluster_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #3: Manage Kafka cluster(s) in the same Pulumi Stack using OAuth authentication
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetClusterLinkResult> getClusterLink(GetClusterLinkArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getClusterLink:getClusterLink", TypeShape.of(GetClusterLinkResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ClusterLink` describes a Cluster Link data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .credentials(GetClusterLinkCredentialsArgs.builder()
     *                 .key(app_manager_west_cluster_api_key.id())
     *                 .secret(app_manager_west_cluster_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #3: Manage Kafka cluster(s) in the same Pulumi Stack using OAuth authentication
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkArgs;
     * import com.pulumi.confluentcloud.inputs.GetClusterLinkKafkaClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getClusterLink(GetClusterLinkArgs.builder()
     *             .linkName("main-link")
     *             .restEndpoint(west.restEndpoint())
     *             .kafkaCluster(GetClusterLinkKafkaClusterArgs.builder()
     *                 .id(west.id())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("kafkaClusterLinkId", main.clusterLinkId());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetClusterLinkResult> getClusterLinkPlain(GetClusterLinkPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getClusterLink:getClusterLink", TypeShape.of(GetClusterLinkResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ConnectArtifact` data source represents a Connect Artifact in Confluent Cloud. Connect Artifacts are used to store and manage custom connector plugins in Confluent Cloud.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getConnectArtifact(GetConnectArtifactArgs.builder()
     *             .id("ca-123456")
     *             .environment(GetConnectArtifactEnvironmentArgs.builder()
     *                 .id("env-123456")
     *                 .build())
     *             .cloud("AWS")
     *             .build());
     * 
     *         ctx.export("artifactName", example.displayName());
     *         ctx.export("artifactCloud", example.cloud());
     *         ctx.export("artifactContentFormat", example.contentFormat());
     *         ctx.export("artifactDescription", example.description());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetConnectArtifactResult> getConnectArtifact(GetConnectArtifactArgs args) {
        return getConnectArtifact(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ConnectArtifact` data source represents a Connect Artifact in Confluent Cloud. Connect Artifacts are used to store and manage custom connector plugins in Confluent Cloud.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getConnectArtifact(GetConnectArtifactArgs.builder()
     *             .id("ca-123456")
     *             .environment(GetConnectArtifactEnvironmentArgs.builder()
     *                 .id("env-123456")
     *                 .build())
     *             .cloud("AWS")
     *             .build());
     * 
     *         ctx.export("artifactName", example.displayName());
     *         ctx.export("artifactCloud", example.cloud());
     *         ctx.export("artifactContentFormat", example.contentFormat());
     *         ctx.export("artifactDescription", example.description());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetConnectArtifactResult> getConnectArtifactPlain(GetConnectArtifactPlainArgs args) {
        return getConnectArtifactPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ConnectArtifact` data source represents a Connect Artifact in Confluent Cloud. Connect Artifacts are used to store and manage custom connector plugins in Confluent Cloud.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getConnectArtifact(GetConnectArtifactArgs.builder()
     *             .id("ca-123456")
     *             .environment(GetConnectArtifactEnvironmentArgs.builder()
     *                 .id("env-123456")
     *                 .build())
     *             .cloud("AWS")
     *             .build());
     * 
     *         ctx.export("artifactName", example.displayName());
     *         ctx.export("artifactCloud", example.cloud());
     *         ctx.export("artifactContentFormat", example.contentFormat());
     *         ctx.export("artifactDescription", example.description());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetConnectArtifactResult> getConnectArtifact(GetConnectArtifactArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getConnectArtifact:getConnectArtifact", TypeShape.of(GetConnectArtifactResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ConnectArtifact` data source represents a Connect Artifact in Confluent Cloud. Connect Artifacts are used to store and manage custom connector plugins in Confluent Cloud.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getConnectArtifact(GetConnectArtifactArgs.builder()
     *             .id("ca-123456")
     *             .environment(GetConnectArtifactEnvironmentArgs.builder()
     *                 .id("env-123456")
     *                 .build())
     *             .cloud("AWS")
     *             .build());
     * 
     *         ctx.export("artifactName", example.displayName());
     *         ctx.export("artifactCloud", example.cloud());
     *         ctx.export("artifactContentFormat", example.contentFormat());
     *         ctx.export("artifactDescription", example.description());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetConnectArtifactResult> getConnectArtifact(GetConnectArtifactArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getConnectArtifact:getConnectArtifact", TypeShape.of(GetConnectArtifactResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ConnectArtifact` data source represents a Connect Artifact in Confluent Cloud. Connect Artifacts are used to store and manage custom connector plugins in Confluent Cloud.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetConnectArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getConnectArtifact(GetConnectArtifactArgs.builder()
     *             .id("ca-123456")
     *             .environment(GetConnectArtifactEnvironmentArgs.builder()
     *                 .id("env-123456")
     *                 .build())
     *             .cloud("AWS")
     *             .build());
     * 
     *         ctx.export("artifactName", example.displayName());
     *         ctx.export("artifactCloud", example.cloud());
     *         ctx.export("artifactContentFormat", example.contentFormat());
     *         ctx.export("artifactDescription", example.description());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetConnectArtifactResult> getConnectArtifactPlain(GetConnectArtifactPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getConnectArtifact:getConnectArtifact", TypeShape.of(GetConnectArtifactResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.DnsRecord` describes a DNS Record data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordArgs;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getDnsRecord(GetDnsRecordArgs.builder()
     *             .id("dnsrec-abc123")
     *             .environment(GetDnsRecordEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("dnsRecord", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetDnsRecordResult> getDnsRecord(GetDnsRecordArgs args) {
        return getDnsRecord(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.DnsRecord` describes a DNS Record data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordArgs;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getDnsRecord(GetDnsRecordArgs.builder()
     *             .id("dnsrec-abc123")
     *             .environment(GetDnsRecordEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("dnsRecord", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetDnsRecordResult> getDnsRecordPlain(GetDnsRecordPlainArgs args) {
        return getDnsRecordPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.DnsRecord` describes a DNS Record data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordArgs;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getDnsRecord(GetDnsRecordArgs.builder()
     *             .id("dnsrec-abc123")
     *             .environment(GetDnsRecordEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("dnsRecord", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetDnsRecordResult> getDnsRecord(GetDnsRecordArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getDnsRecord:getDnsRecord", TypeShape.of(GetDnsRecordResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.DnsRecord` describes a DNS Record data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordArgs;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getDnsRecord(GetDnsRecordArgs.builder()
     *             .id("dnsrec-abc123")
     *             .environment(GetDnsRecordEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("dnsRecord", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetDnsRecordResult> getDnsRecord(GetDnsRecordArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getDnsRecord:getDnsRecord", TypeShape.of(GetDnsRecordResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.DnsRecord` describes a DNS Record data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordArgs;
     * import com.pulumi.confluentcloud.inputs.GetDnsRecordEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getDnsRecord(GetDnsRecordArgs.builder()
     *             .id("dnsrec-abc123")
     *             .environment(GetDnsRecordEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("dnsRecord", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetDnsRecordResult> getDnsRecordPlain(GetDnsRecordPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getDnsRecord:getDnsRecord", TypeShape.of(GetDnsRecordResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Environment` describes an Environment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .id("env-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .displayName("stag")
     *             .build());
     * 
     *         final var exampleUsingNameGetServiceAccount = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingNameGetServiceAccount.id()))
     *             .roleName("EnvironmentAdmin")
     *             .crnPattern(exampleUsingName.resourceName())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetEnvironmentResult> getEnvironment() {
        return getEnvironment(GetEnvironmentArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Environment` describes an Environment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .id("env-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .displayName("stag")
     *             .build());
     * 
     *         final var exampleUsingNameGetServiceAccount = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingNameGetServiceAccount.id()))
     *             .roleName("EnvironmentAdmin")
     *             .crnPattern(exampleUsingName.resourceName())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetEnvironmentResult> getEnvironmentPlain() {
        return getEnvironmentPlain(GetEnvironmentPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Environment` describes an Environment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .id("env-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .displayName("stag")
     *             .build());
     * 
     *         final var exampleUsingNameGetServiceAccount = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingNameGetServiceAccount.id()))
     *             .roleName("EnvironmentAdmin")
     *             .crnPattern(exampleUsingName.resourceName())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetEnvironmentResult> getEnvironment(GetEnvironmentArgs args) {
        return getEnvironment(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Environment` describes an Environment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .id("env-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .displayName("stag")
     *             .build());
     * 
     *         final var exampleUsingNameGetServiceAccount = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingNameGetServiceAccount.id()))
     *             .roleName("EnvironmentAdmin")
     *             .crnPattern(exampleUsingName.resourceName())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetEnvironmentResult> getEnvironmentPlain(GetEnvironmentPlainArgs args) {
        return getEnvironmentPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Environment` describes an Environment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .id("env-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .displayName("stag")
     *             .build());
     * 
     *         final var exampleUsingNameGetServiceAccount = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingNameGetServiceAccount.id()))
     *             .roleName("EnvironmentAdmin")
     *             .crnPattern(exampleUsingName.resourceName())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetEnvironmentResult> getEnvironment(GetEnvironmentArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getEnvironment:getEnvironment", TypeShape.of(GetEnvironmentResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Environment` describes an Environment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .id("env-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .displayName("stag")
     *             .build());
     * 
     *         final var exampleUsingNameGetServiceAccount = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingNameGetServiceAccount.id()))
     *             .roleName("EnvironmentAdmin")
     *             .crnPattern(exampleUsingName.resourceName())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetEnvironmentResult> getEnvironment(GetEnvironmentArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getEnvironment:getEnvironment", TypeShape.of(GetEnvironmentResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Environment` describes an Environment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .id("env-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getEnvironment(GetEnvironmentArgs.builder()
     *             .displayName("stag")
     *             .build());
     * 
     *         final var exampleUsingNameGetServiceAccount = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingNameGetServiceAccount.id()))
     *             .roleName("EnvironmentAdmin")
     *             .crnPattern(exampleUsingName.resourceName())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetEnvironmentResult> getEnvironmentPlain(GetEnvironmentPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getEnvironment:getEnvironment", TypeShape.of(GetEnvironmentResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getEnvironments` describes a data source for Environments.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getEnvironments(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("environments", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetEnvironmentsResult> getEnvironments() {
        return getEnvironments(InvokeArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getEnvironments` describes a data source for Environments.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getEnvironments(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("environments", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetEnvironmentsResult> getEnvironmentsPlain() {
        return getEnvironmentsPlain(InvokeArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getEnvironments` describes a data source for Environments.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getEnvironments(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("environments", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetEnvironmentsResult> getEnvironments(InvokeArgs args) {
        return getEnvironments(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getEnvironments` describes a data source for Environments.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getEnvironments(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("environments", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetEnvironmentsResult> getEnvironmentsPlain(InvokeArgs args) {
        return getEnvironmentsPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getEnvironments` describes a data source for Environments.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getEnvironments(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("environments", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetEnvironmentsResult> getEnvironments(InvokeArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getEnvironments:getEnvironments", TypeShape.of(GetEnvironmentsResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getEnvironments` describes a data source for Environments.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getEnvironments(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("environments", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetEnvironmentsResult> getEnvironments(InvokeArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getEnvironments:getEnvironments", TypeShape.of(GetEnvironmentsResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getEnvironments` describes a data source for Environments.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getEnvironments(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("environments", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetEnvironmentsResult> getEnvironmentsPlain(InvokeArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getEnvironments:getEnvironments", TypeShape.of(GetEnvironmentsResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkArtifact` describes a Flink Artifact data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .id("lfa-abc123")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .displayName("my_artifact")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetFlinkArtifactResult> getFlinkArtifact(GetFlinkArtifactArgs args) {
        return getFlinkArtifact(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkArtifact` describes a Flink Artifact data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .id("lfa-abc123")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .displayName("my_artifact")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetFlinkArtifactResult> getFlinkArtifactPlain(GetFlinkArtifactPlainArgs args) {
        return getFlinkArtifactPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkArtifact` describes a Flink Artifact data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .id("lfa-abc123")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .displayName("my_artifact")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetFlinkArtifactResult> getFlinkArtifact(GetFlinkArtifactArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getFlinkArtifact:getFlinkArtifact", TypeShape.of(GetFlinkArtifactResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkArtifact` describes a Flink Artifact data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .id("lfa-abc123")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .displayName("my_artifact")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetFlinkArtifactResult> getFlinkArtifact(GetFlinkArtifactArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getFlinkArtifact:getFlinkArtifact", TypeShape.of(GetFlinkArtifactResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkArtifact` describes a Flink Artifact data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkArtifactEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .id("lfa-abc123")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkArtifact(GetFlinkArtifactArgs.builder()
     *             .displayName("my_artifact")
     *             .environment(GetFlinkArtifactEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetFlinkArtifactResult> getFlinkArtifactPlain(GetFlinkArtifactPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getFlinkArtifact:getFlinkArtifact", TypeShape.of(GetFlinkArtifactResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkComputePool` describes a Flink Compute Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .id("lfcp-abc123")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .displayName("my_compute_pool")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetFlinkComputePoolResult> getFlinkComputePool(GetFlinkComputePoolArgs args) {
        return getFlinkComputePool(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkComputePool` describes a Flink Compute Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .id("lfcp-abc123")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .displayName("my_compute_pool")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetFlinkComputePoolResult> getFlinkComputePoolPlain(GetFlinkComputePoolPlainArgs args) {
        return getFlinkComputePoolPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkComputePool` describes a Flink Compute Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .id("lfcp-abc123")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .displayName("my_compute_pool")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetFlinkComputePoolResult> getFlinkComputePool(GetFlinkComputePoolArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getFlinkComputePool:getFlinkComputePool", TypeShape.of(GetFlinkComputePoolResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkComputePool` describes a Flink Compute Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .id("lfcp-abc123")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .displayName("my_compute_pool")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetFlinkComputePoolResult> getFlinkComputePool(GetFlinkComputePoolArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getFlinkComputePool:getFlinkComputePool", TypeShape.of(GetFlinkComputePoolResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkComputePool` describes a Flink Compute Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetFlinkComputePoolEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .id("lfcp-abc123")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getFlinkComputePool(GetFlinkComputePoolArgs.builder()
     *             .displayName("my_compute_pool")
     *             .environment(GetFlinkComputePoolEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetFlinkComputePoolResult> getFlinkComputePoolPlain(GetFlinkComputePoolPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getFlinkComputePool:getFlinkComputePool", TypeShape.of(GetFlinkComputePoolResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkConnection` describes a Flink Connection data source.
     * 
     * ## Example Usage
     * 
     */
    public static Output<GetFlinkConnectionResult> getFlinkConnection(GetFlinkConnectionArgs args) {
        return getFlinkConnection(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkConnection` describes a Flink Connection data source.
     * 
     * ## Example Usage
     * 
     */
    public static CompletableFuture<GetFlinkConnectionResult> getFlinkConnectionPlain(GetFlinkConnectionPlainArgs args) {
        return getFlinkConnectionPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkConnection` describes a Flink Connection data source.
     * 
     * ## Example Usage
     * 
     */
    public static Output<GetFlinkConnectionResult> getFlinkConnection(GetFlinkConnectionArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getFlinkConnection:getFlinkConnection", TypeShape.of(GetFlinkConnectionResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkConnection` describes a Flink Connection data source.
     * 
     * ## Example Usage
     * 
     */
    public static Output<GetFlinkConnectionResult> getFlinkConnection(GetFlinkConnectionArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getFlinkConnection:getFlinkConnection", TypeShape.of(GetFlinkConnectionResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.FlinkConnection` describes a Flink Connection data source.
     * 
     * ## Example Usage
     * 
     */
    public static CompletableFuture<GetFlinkConnectionResult> getFlinkConnectionPlain(GetFlinkConnectionPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getFlinkConnection:getFlinkConnection", TypeShape.of(GetFlinkConnectionResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getFlinkRegion` describes a Flink cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkRegionArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getFlinkRegion(GetFlinkRegionArgs.builder()
     *             .cloud("AWS")
     *             .region("us-east-1")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetFlinkRegionResult> getFlinkRegion(GetFlinkRegionArgs args) {
        return getFlinkRegion(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getFlinkRegion` describes a Flink cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkRegionArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getFlinkRegion(GetFlinkRegionArgs.builder()
     *             .cloud("AWS")
     *             .region("us-east-1")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetFlinkRegionResult> getFlinkRegionPlain(GetFlinkRegionPlainArgs args) {
        return getFlinkRegionPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getFlinkRegion` describes a Flink cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkRegionArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getFlinkRegion(GetFlinkRegionArgs.builder()
     *             .cloud("AWS")
     *             .region("us-east-1")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetFlinkRegionResult> getFlinkRegion(GetFlinkRegionArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getFlinkRegion:getFlinkRegion", TypeShape.of(GetFlinkRegionResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getFlinkRegion` describes a Flink cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkRegionArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getFlinkRegion(GetFlinkRegionArgs.builder()
     *             .cloud("AWS")
     *             .region("us-east-1")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetFlinkRegionResult> getFlinkRegion(GetFlinkRegionArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getFlinkRegion:getFlinkRegion", TypeShape.of(GetFlinkRegionResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getFlinkRegion` describes a Flink cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetFlinkRegionArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getFlinkRegion(GetFlinkRegionArgs.builder()
     *             .cloud("AWS")
     *             .region("us-east-1")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetFlinkRegionResult> getFlinkRegionPlain(GetFlinkRegionPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getFlinkRegion:getFlinkRegion", TypeShape.of(GetFlinkRegionResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Gateway` describes a Gateway data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGatewayArgs;
     * import com.pulumi.confluentcloud.inputs.GetGatewayEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getGateway(GetGatewayArgs.builder()
     *             .id("gw-abc123")
     *             .environment(GetGatewayEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gateway", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetGatewayResult> getGateway(GetGatewayArgs args) {
        return getGateway(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Gateway` describes a Gateway data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGatewayArgs;
     * import com.pulumi.confluentcloud.inputs.GetGatewayEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getGateway(GetGatewayArgs.builder()
     *             .id("gw-abc123")
     *             .environment(GetGatewayEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gateway", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetGatewayResult> getGatewayPlain(GetGatewayPlainArgs args) {
        return getGatewayPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Gateway` describes a Gateway data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGatewayArgs;
     * import com.pulumi.confluentcloud.inputs.GetGatewayEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getGateway(GetGatewayArgs.builder()
     *             .id("gw-abc123")
     *             .environment(GetGatewayEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gateway", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetGatewayResult> getGateway(GetGatewayArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getGateway:getGateway", TypeShape.of(GetGatewayResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Gateway` describes a Gateway data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGatewayArgs;
     * import com.pulumi.confluentcloud.inputs.GetGatewayEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getGateway(GetGatewayArgs.builder()
     *             .id("gw-abc123")
     *             .environment(GetGatewayEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gateway", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetGatewayResult> getGateway(GetGatewayArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getGateway:getGateway", TypeShape.of(GetGatewayResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Gateway` describes a Gateway data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGatewayArgs;
     * import com.pulumi.confluentcloud.inputs.GetGatewayEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getGateway(GetGatewayArgs.builder()
     *             .id("gw-abc123")
     *             .environment(GetGatewayEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gateway", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetGatewayResult> getGatewayPlain(GetGatewayPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getGateway:getGateway", TypeShape.of(GetGatewayResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.GroupMapping` describes a Group Mapping data source.
     * 
     * &gt; **Note:** See [Group Mapping in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/authenticate/sso/group-mapping/overview.html) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGroupMappingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .id("group-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .displayName("Default")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetGroupMappingResult> getGroupMapping() {
        return getGroupMapping(GetGroupMappingArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.GroupMapping` describes a Group Mapping data source.
     * 
     * &gt; **Note:** See [Group Mapping in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/authenticate/sso/group-mapping/overview.html) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGroupMappingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .id("group-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .displayName("Default")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetGroupMappingResult> getGroupMappingPlain() {
        return getGroupMappingPlain(GetGroupMappingPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.GroupMapping` describes a Group Mapping data source.
     * 
     * &gt; **Note:** See [Group Mapping in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/authenticate/sso/group-mapping/overview.html) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGroupMappingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .id("group-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .displayName("Default")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetGroupMappingResult> getGroupMapping(GetGroupMappingArgs args) {
        return getGroupMapping(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.GroupMapping` describes a Group Mapping data source.
     * 
     * &gt; **Note:** See [Group Mapping in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/authenticate/sso/group-mapping/overview.html) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGroupMappingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .id("group-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .displayName("Default")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetGroupMappingResult> getGroupMappingPlain(GetGroupMappingPlainArgs args) {
        return getGroupMappingPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.GroupMapping` describes a Group Mapping data source.
     * 
     * &gt; **Note:** See [Group Mapping in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/authenticate/sso/group-mapping/overview.html) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGroupMappingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .id("group-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .displayName("Default")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetGroupMappingResult> getGroupMapping(GetGroupMappingArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getGroupMapping:getGroupMapping", TypeShape.of(GetGroupMappingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.GroupMapping` describes a Group Mapping data source.
     * 
     * &gt; **Note:** See [Group Mapping in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/authenticate/sso/group-mapping/overview.html) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGroupMappingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .id("group-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .displayName("Default")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetGroupMappingResult> getGroupMapping(GetGroupMappingArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getGroupMapping:getGroupMapping", TypeShape.of(GetGroupMappingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.GroupMapping` describes a Group Mapping data source.
     * 
     * &gt; **Note:** See [Group Mapping in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/authenticate/sso/group-mapping/overview.html) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetGroupMappingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .id("group-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getGroupMapping(GetGroupMappingArgs.builder()
     *             .displayName("Default")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetGroupMappingResult> getGroupMappingPlain(GetGroupMappingPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getGroupMapping:getGroupMapping", TypeShape.of(GetGroupMappingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityPool` describes an Identity Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .id("pool-xyz456")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .displayName("My Identity Pool")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIdentityPoolResult> getIdentityPool(GetIdentityPoolArgs args) {
        return getIdentityPool(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityPool` describes an Identity Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .id("pool-xyz456")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .displayName("My Identity Pool")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIdentityPoolResult> getIdentityPoolPlain(GetIdentityPoolPlainArgs args) {
        return getIdentityPoolPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityPool` describes an Identity Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .id("pool-xyz456")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .displayName("My Identity Pool")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIdentityPoolResult> getIdentityPool(GetIdentityPoolArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIdentityPool:getIdentityPool", TypeShape.of(GetIdentityPoolResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityPool` describes an Identity Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .id("pool-xyz456")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .displayName("My Identity Pool")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIdentityPoolResult> getIdentityPool(GetIdentityPoolArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIdentityPool:getIdentityPool", TypeShape.of(GetIdentityPoolResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityPool` describes an Identity Pool data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolArgs;
     * import com.pulumi.confluentcloud.inputs.GetIdentityPoolIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .id("pool-xyz456")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityPool(GetIdentityPoolArgs.builder()
     *             .displayName("My Identity Pool")
     *             .identityProvider(GetIdentityPoolIdentityProviderArgs.builder()
     *                 .id("op-abc123")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIdentityPoolResult> getIdentityPoolPlain(GetIdentityPoolPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getIdentityPool:getIdentityPool", TypeShape.of(GetIdentityPoolResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityProvider` describes an Identity Provider data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .displayName("My OIDC Provider: Azure AD")
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIdentityProviderResult> getIdentityProvider() {
        return getIdentityProvider(GetIdentityProviderArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityProvider` describes an Identity Provider data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .displayName("My OIDC Provider: Azure AD")
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIdentityProviderResult> getIdentityProviderPlain() {
        return getIdentityProviderPlain(GetIdentityProviderPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityProvider` describes an Identity Provider data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .displayName("My OIDC Provider: Azure AD")
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIdentityProviderResult> getIdentityProvider(GetIdentityProviderArgs args) {
        return getIdentityProvider(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityProvider` describes an Identity Provider data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .displayName("My OIDC Provider: Azure AD")
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIdentityProviderResult> getIdentityProviderPlain(GetIdentityProviderPlainArgs args) {
        return getIdentityProviderPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityProvider` describes an Identity Provider data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .displayName("My OIDC Provider: Azure AD")
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIdentityProviderResult> getIdentityProvider(GetIdentityProviderArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIdentityProvider:getIdentityProvider", TypeShape.of(GetIdentityProviderResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityProvider` describes an Identity Provider data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .displayName("My OIDC Provider: Azure AD")
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIdentityProviderResult> getIdentityProvider(GetIdentityProviderArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIdentityProvider:getIdentityProvider", TypeShape.of(GetIdentityProviderResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IdentityProvider` describes an Identity Provider data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIdentityProviderArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .id("op-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getIdentityProvider(GetIdentityProviderArgs.builder()
     *             .displayName("My OIDC Provider: Azure AD")
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIdentityProviderResult> getIdentityProviderPlain(GetIdentityProviderPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getIdentityProvider:getIdentityProvider", TypeShape.of(GetIdentityProviderResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Invitation` describes an Invitation data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetInvitationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getInvitation(GetInvitationArgs.builder()
     *             .id("i-gxxn1")
     *             .build());
     * 
     *         ctx.export("invitation", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetInvitationResult> getInvitation(GetInvitationArgs args) {
        return getInvitation(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Invitation` describes an Invitation data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetInvitationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getInvitation(GetInvitationArgs.builder()
     *             .id("i-gxxn1")
     *             .build());
     * 
     *         ctx.export("invitation", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetInvitationResult> getInvitationPlain(GetInvitationPlainArgs args) {
        return getInvitationPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Invitation` describes an Invitation data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetInvitationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getInvitation(GetInvitationArgs.builder()
     *             .id("i-gxxn1")
     *             .build());
     * 
     *         ctx.export("invitation", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetInvitationResult> getInvitation(GetInvitationArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getInvitation:getInvitation", TypeShape.of(GetInvitationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Invitation` describes an Invitation data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetInvitationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getInvitation(GetInvitationArgs.builder()
     *             .id("i-gxxn1")
     *             .build());
     * 
     *         ctx.export("invitation", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetInvitationResult> getInvitation(GetInvitationArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getInvitation:getInvitation", TypeShape.of(GetInvitationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Invitation` describes an Invitation data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetInvitationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getInvitation(GetInvitationArgs.builder()
     *             .id("i-gxxn1")
     *             .build());
     * 
     *         ctx.export("invitation", main);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetInvitationResult> getInvitationPlain(GetInvitationPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getInvitation:getInvitation", TypeShape.of(GetInvitationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![Preview](https://img.shields.io/badge/Lifecycle%20Stage-Preview-%2300afba)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * &gt; **Note:** `confluentcloud.getIpAddresses` data source is available in **Preview** for early adopters. Preview features are introduced to gather customer feedback. This feature should be used only for evaluation and non-production testing purposes or to provide feedback to Confluent, particularly as it becomes more widely available in follow-on editions.\
     * **Preview** features are intended for evaluation use in development and testing environments only, and not for production use. The warranty, SLA, and Support Services provisions of your agreement with Confluent do not apply to Preview features. Preview features are considered to be a Proof of Concept as defined in the Confluent Cloud Terms of Service. Confluent may discontinue providing preview releases of the Preview features at any time in Confluents sole discretion.
     * 
     * `confluentcloud.getIpAddresses` describes IP Addresses data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesArgs;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getIpAddresses(GetIpAddressesArgs.builder()
     *             .filter(GetIpAddressesFilterArgs.builder()
     *                 .clouds("AWS")
     *                 .regions(                
     *                     "us-east-1",
     *                     "us-east-2")
     *                 .services("KAFKA")
     *                 .addressTypes("EGRESS")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("ipAddresses", main.ipAddresses());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpAddressesResult> getIpAddresses() {
        return getIpAddresses(GetIpAddressesArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![Preview](https://img.shields.io/badge/Lifecycle%20Stage-Preview-%2300afba)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * &gt; **Note:** `confluentcloud.getIpAddresses` data source is available in **Preview** for early adopters. Preview features are introduced to gather customer feedback. This feature should be used only for evaluation and non-production testing purposes or to provide feedback to Confluent, particularly as it becomes more widely available in follow-on editions.\
     * **Preview** features are intended for evaluation use in development and testing environments only, and not for production use. The warranty, SLA, and Support Services provisions of your agreement with Confluent do not apply to Preview features. Preview features are considered to be a Proof of Concept as defined in the Confluent Cloud Terms of Service. Confluent may discontinue providing preview releases of the Preview features at any time in Confluents sole discretion.
     * 
     * `confluentcloud.getIpAddresses` describes IP Addresses data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesArgs;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getIpAddresses(GetIpAddressesArgs.builder()
     *             .filter(GetIpAddressesFilterArgs.builder()
     *                 .clouds("AWS")
     *                 .regions(                
     *                     "us-east-1",
     *                     "us-east-2")
     *                 .services("KAFKA")
     *                 .addressTypes("EGRESS")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("ipAddresses", main.ipAddresses());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIpAddressesResult> getIpAddressesPlain() {
        return getIpAddressesPlain(GetIpAddressesPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![Preview](https://img.shields.io/badge/Lifecycle%20Stage-Preview-%2300afba)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * &gt; **Note:** `confluentcloud.getIpAddresses` data source is available in **Preview** for early adopters. Preview features are introduced to gather customer feedback. This feature should be used only for evaluation and non-production testing purposes or to provide feedback to Confluent, particularly as it becomes more widely available in follow-on editions.\
     * **Preview** features are intended for evaluation use in development and testing environments only, and not for production use. The warranty, SLA, and Support Services provisions of your agreement with Confluent do not apply to Preview features. Preview features are considered to be a Proof of Concept as defined in the Confluent Cloud Terms of Service. Confluent may discontinue providing preview releases of the Preview features at any time in Confluents sole discretion.
     * 
     * `confluentcloud.getIpAddresses` describes IP Addresses data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesArgs;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getIpAddresses(GetIpAddressesArgs.builder()
     *             .filter(GetIpAddressesFilterArgs.builder()
     *                 .clouds("AWS")
     *                 .regions(                
     *                     "us-east-1",
     *                     "us-east-2")
     *                 .services("KAFKA")
     *                 .addressTypes("EGRESS")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("ipAddresses", main.ipAddresses());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpAddressesResult> getIpAddresses(GetIpAddressesArgs args) {
        return getIpAddresses(args, InvokeOptions.Empty);
    }
    /**
     * [![Preview](https://img.shields.io/badge/Lifecycle%20Stage-Preview-%2300afba)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * &gt; **Note:** `confluentcloud.getIpAddresses` data source is available in **Preview** for early adopters. Preview features are introduced to gather customer feedback. This feature should be used only for evaluation and non-production testing purposes or to provide feedback to Confluent, particularly as it becomes more widely available in follow-on editions.\
     * **Preview** features are intended for evaluation use in development and testing environments only, and not for production use. The warranty, SLA, and Support Services provisions of your agreement with Confluent do not apply to Preview features. Preview features are considered to be a Proof of Concept as defined in the Confluent Cloud Terms of Service. Confluent may discontinue providing preview releases of the Preview features at any time in Confluents sole discretion.
     * 
     * `confluentcloud.getIpAddresses` describes IP Addresses data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesArgs;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getIpAddresses(GetIpAddressesArgs.builder()
     *             .filter(GetIpAddressesFilterArgs.builder()
     *                 .clouds("AWS")
     *                 .regions(                
     *                     "us-east-1",
     *                     "us-east-2")
     *                 .services("KAFKA")
     *                 .addressTypes("EGRESS")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("ipAddresses", main.ipAddresses());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIpAddressesResult> getIpAddressesPlain(GetIpAddressesPlainArgs args) {
        return getIpAddressesPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![Preview](https://img.shields.io/badge/Lifecycle%20Stage-Preview-%2300afba)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * &gt; **Note:** `confluentcloud.getIpAddresses` data source is available in **Preview** for early adopters. Preview features are introduced to gather customer feedback. This feature should be used only for evaluation and non-production testing purposes or to provide feedback to Confluent, particularly as it becomes more widely available in follow-on editions.\
     * **Preview** features are intended for evaluation use in development and testing environments only, and not for production use. The warranty, SLA, and Support Services provisions of your agreement with Confluent do not apply to Preview features. Preview features are considered to be a Proof of Concept as defined in the Confluent Cloud Terms of Service. Confluent may discontinue providing preview releases of the Preview features at any time in Confluents sole discretion.
     * 
     * `confluentcloud.getIpAddresses` describes IP Addresses data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesArgs;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getIpAddresses(GetIpAddressesArgs.builder()
     *             .filter(GetIpAddressesFilterArgs.builder()
     *                 .clouds("AWS")
     *                 .regions(                
     *                     "us-east-1",
     *                     "us-east-2")
     *                 .services("KAFKA")
     *                 .addressTypes("EGRESS")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("ipAddresses", main.ipAddresses());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpAddressesResult> getIpAddresses(GetIpAddressesArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIpAddresses:getIpAddresses", TypeShape.of(GetIpAddressesResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![Preview](https://img.shields.io/badge/Lifecycle%20Stage-Preview-%2300afba)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * &gt; **Note:** `confluentcloud.getIpAddresses` data source is available in **Preview** for early adopters. Preview features are introduced to gather customer feedback. This feature should be used only for evaluation and non-production testing purposes or to provide feedback to Confluent, particularly as it becomes more widely available in follow-on editions.\
     * **Preview** features are intended for evaluation use in development and testing environments only, and not for production use. The warranty, SLA, and Support Services provisions of your agreement with Confluent do not apply to Preview features. Preview features are considered to be a Proof of Concept as defined in the Confluent Cloud Terms of Service. Confluent may discontinue providing preview releases of the Preview features at any time in Confluents sole discretion.
     * 
     * `confluentcloud.getIpAddresses` describes IP Addresses data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesArgs;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getIpAddresses(GetIpAddressesArgs.builder()
     *             .filter(GetIpAddressesFilterArgs.builder()
     *                 .clouds("AWS")
     *                 .regions(                
     *                     "us-east-1",
     *                     "us-east-2")
     *                 .services("KAFKA")
     *                 .addressTypes("EGRESS")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("ipAddresses", main.ipAddresses());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpAddressesResult> getIpAddresses(GetIpAddressesArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIpAddresses:getIpAddresses", TypeShape.of(GetIpAddressesResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![Preview](https://img.shields.io/badge/Lifecycle%20Stage-Preview-%2300afba)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * &gt; **Note:** `confluentcloud.getIpAddresses` data source is available in **Preview** for early adopters. Preview features are introduced to gather customer feedback. This feature should be used only for evaluation and non-production testing purposes or to provide feedback to Confluent, particularly as it becomes more widely available in follow-on editions.\
     * **Preview** features are intended for evaluation use in development and testing environments only, and not for production use. The warranty, SLA, and Support Services provisions of your agreement with Confluent do not apply to Preview features. Preview features are considered to be a Proof of Concept as defined in the Confluent Cloud Terms of Service. Confluent may discontinue providing preview releases of the Preview features at any time in Confluents sole discretion.
     * 
     * `confluentcloud.getIpAddresses` describes IP Addresses data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesArgs;
     * import com.pulumi.confluentcloud.inputs.GetIpAddressesFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getIpAddresses(GetIpAddressesArgs.builder()
     *             .filter(GetIpAddressesFilterArgs.builder()
     *                 .clouds("AWS")
     *                 .regions(                
     *                     "us-east-1",
     *                     "us-east-2")
     *                 .services("KAFKA")
     *                 .addressTypes("EGRESS")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("ipAddresses", main.ipAddresses());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIpAddressesResult> getIpAddressesPlain(GetIpAddressesPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getIpAddresses:getIpAddresses", TypeShape.of(GetIpAddressesResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpFilter` describes an IP Filter data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpFilter(GetIpFilterArgs.builder()
     *             .id("ipf-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpFilterResult> getIpFilter(GetIpFilterArgs args) {
        return getIpFilter(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpFilter` describes an IP Filter data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpFilter(GetIpFilterArgs.builder()
     *             .id("ipf-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIpFilterResult> getIpFilterPlain(GetIpFilterPlainArgs args) {
        return getIpFilterPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpFilter` describes an IP Filter data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpFilter(GetIpFilterArgs.builder()
     *             .id("ipf-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpFilterResult> getIpFilter(GetIpFilterArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIpFilter:getIpFilter", TypeShape.of(GetIpFilterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpFilter` describes an IP Filter data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpFilter(GetIpFilterArgs.builder()
     *             .id("ipf-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpFilterResult> getIpFilter(GetIpFilterArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIpFilter:getIpFilter", TypeShape.of(GetIpFilterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpFilter` describes an IP Filter data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpFilter(GetIpFilterArgs.builder()
     *             .id("ipf-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIpFilterResult> getIpFilterPlain(GetIpFilterPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getIpFilter:getIpFilter", TypeShape.of(GetIpFilterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpGroup` describes an IP Group data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpGroup(GetIpGroupArgs.builder()
     *             .id("ipg-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpGroupResult> getIpGroup(GetIpGroupArgs args) {
        return getIpGroup(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpGroup` describes an IP Group data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpGroup(GetIpGroupArgs.builder()
     *             .id("ipg-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIpGroupResult> getIpGroupPlain(GetIpGroupPlainArgs args) {
        return getIpGroupPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpGroup` describes an IP Group data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpGroup(GetIpGroupArgs.builder()
     *             .id("ipg-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpGroupResult> getIpGroup(GetIpGroupArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIpGroup:getIpGroup", TypeShape.of(GetIpGroupResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpGroup` describes an IP Group data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpGroup(GetIpGroupArgs.builder()
     *             .id("ipg-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetIpGroupResult> getIpGroup(GetIpGroupArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getIpGroup:getIpGroup", TypeShape.of(GetIpGroupResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.IpGroup` describes an IP Group data source.
     * 
     * &gt; **Note:** See [IP Filtering on Confluent Cloud](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/overview.html) for more details about the IP Filtering feature, its prerequisites, and its limitations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetIpGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getIpGroup(GetIpGroupArgs.builder()
     *             .id("ipg-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetIpGroupResult> getIpGroupPlain(GetIpGroupPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getIpGroup:getIpGroup", TypeShape.of(GetIpGroupResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaClientQuota` describes a Kafka Client Quota.
     * 
     * &gt; **Note:** See [Control application usage with Client Quotas](https://docs.confluent.io/cloud/current/clusters/client-quotas.html#control-application-usage-with-client-quotas) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClientQuotaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getKafkaClientQuota(GetKafkaClientQuotaArgs.builder()
     *             .id("cq-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaClientQuotaResult> getKafkaClientQuota(GetKafkaClientQuotaArgs args) {
        return getKafkaClientQuota(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaClientQuota` describes a Kafka Client Quota.
     * 
     * &gt; **Note:** See [Control application usage with Client Quotas](https://docs.confluent.io/cloud/current/clusters/client-quotas.html#control-application-usage-with-client-quotas) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClientQuotaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getKafkaClientQuota(GetKafkaClientQuotaArgs.builder()
     *             .id("cq-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKafkaClientQuotaResult> getKafkaClientQuotaPlain(GetKafkaClientQuotaPlainArgs args) {
        return getKafkaClientQuotaPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaClientQuota` describes a Kafka Client Quota.
     * 
     * &gt; **Note:** See [Control application usage with Client Quotas](https://docs.confluent.io/cloud/current/clusters/client-quotas.html#control-application-usage-with-client-quotas) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClientQuotaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getKafkaClientQuota(GetKafkaClientQuotaArgs.builder()
     *             .id("cq-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaClientQuotaResult> getKafkaClientQuota(GetKafkaClientQuotaArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKafkaClientQuota:getKafkaClientQuota", TypeShape.of(GetKafkaClientQuotaResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaClientQuota` describes a Kafka Client Quota.
     * 
     * &gt; **Note:** See [Control application usage with Client Quotas](https://docs.confluent.io/cloud/current/clusters/client-quotas.html#control-application-usage-with-client-quotas) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClientQuotaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getKafkaClientQuota(GetKafkaClientQuotaArgs.builder()
     *             .id("cq-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaClientQuotaResult> getKafkaClientQuota(GetKafkaClientQuotaArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKafkaClientQuota:getKafkaClientQuota", TypeShape.of(GetKafkaClientQuotaResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaClientQuota` describes a Kafka Client Quota.
     * 
     * &gt; **Note:** See [Control application usage with Client Quotas](https://docs.confluent.io/cloud/current/clusters/client-quotas.html#control-application-usage-with-client-quotas) for more details.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClientQuotaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getKafkaClientQuota(GetKafkaClientQuotaArgs.builder()
     *             .id("cq-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKafkaClientQuotaResult> getKafkaClientQuotaPlain(GetKafkaClientQuotaPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getKafkaClientQuota:getKafkaClientQuota", TypeShape.of(GetKafkaClientQuotaResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaCluster` describes a Kafka cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .id("lkc-abc123")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("app_mgr")
     *             .description(String.format("app_mgr for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .displayName("basic_kafka_cluster")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaClusterResult> getKafkaCluster(GetKafkaClusterArgs args) {
        return getKafkaCluster(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaCluster` describes a Kafka cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .id("lkc-abc123")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("app_mgr")
     *             .description(String.format("app_mgr for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .displayName("basic_kafka_cluster")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKafkaClusterResult> getKafkaClusterPlain(GetKafkaClusterPlainArgs args) {
        return getKafkaClusterPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaCluster` describes a Kafka cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .id("lkc-abc123")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("app_mgr")
     *             .description(String.format("app_mgr for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .displayName("basic_kafka_cluster")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaClusterResult> getKafkaCluster(GetKafkaClusterArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKafkaCluster:getKafkaCluster", TypeShape.of(GetKafkaClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaCluster` describes a Kafka cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .id("lkc-abc123")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("app_mgr")
     *             .description(String.format("app_mgr for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .displayName("basic_kafka_cluster")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaClusterResult> getKafkaCluster(GetKafkaClusterArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKafkaCluster:getKafkaCluster", TypeShape.of(GetKafkaClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaCluster` describes a Kafka cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .id("lkc-abc123")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("app_mgr")
     *             .description(String.format("app_mgr for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getKafkaCluster(GetKafkaClusterArgs.builder()
     *             .displayName("basic_kafka_cluster")
     *             .environment(GetKafkaClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKafkaClusterResult> getKafkaClusterPlain(GetKafkaClusterPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getKafkaCluster:getKafkaCluster", TypeShape.of(GetKafkaClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getKafkaClusters` describes a data source for Kafka Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getKafkaClusters(GetKafkaClustersArgs.builder()
     *             .environment(GetKafkaClustersEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaClustersResult> getKafkaClusters(GetKafkaClustersArgs args) {
        return getKafkaClusters(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getKafkaClusters` describes a data source for Kafka Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getKafkaClusters(GetKafkaClustersArgs.builder()
     *             .environment(GetKafkaClustersEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKafkaClustersResult> getKafkaClustersPlain(GetKafkaClustersPlainArgs args) {
        return getKafkaClustersPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getKafkaClusters` describes a data source for Kafka Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getKafkaClusters(GetKafkaClustersArgs.builder()
     *             .environment(GetKafkaClustersEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaClustersResult> getKafkaClusters(GetKafkaClustersArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKafkaClusters:getKafkaClusters", TypeShape.of(GetKafkaClustersResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getKafkaClusters` describes a data source for Kafka Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getKafkaClusters(GetKafkaClustersArgs.builder()
     *             .environment(GetKafkaClustersEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaClustersResult> getKafkaClusters(GetKafkaClustersArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKafkaClusters:getKafkaClusters", TypeShape.of(GetKafkaClustersResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getKafkaClusters` describes a data source for Kafka Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getKafkaClusters(GetKafkaClustersArgs.builder()
     *             .environment(GetKafkaClustersEnvironmentArgs.builder()
     *                 .id("env-123abc")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKafkaClustersResult> getKafkaClustersPlain(GetKafkaClustersPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getKafkaClusters:getKafkaClusters", TypeShape.of(GetKafkaClustersResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaTopic` describes a Kafka Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .kafkaCluster(GetKafkaTopicKafkaClusterArgs.builder()
     *                 .id(basic_cluster.id())
     *                 .build())
     *             .topicName("orders")
     *             .restEndpoint(basic_cluster.restEndpoint())
     *             .credentials(GetKafkaTopicCredentialsArgs.builder()
     *                 .key("<Kafka API Key for confluent_kafka_cluster.basic-cluster>")
     *                 .secret("<Kafka API Secret for confluent_kafka_cluster.basic-cluster>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .topicName("orders")
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaTopicResult> getKafkaTopic(GetKafkaTopicArgs args) {
        return getKafkaTopic(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaTopic` describes a Kafka Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .kafkaCluster(GetKafkaTopicKafkaClusterArgs.builder()
     *                 .id(basic_cluster.id())
     *                 .build())
     *             .topicName("orders")
     *             .restEndpoint(basic_cluster.restEndpoint())
     *             .credentials(GetKafkaTopicCredentialsArgs.builder()
     *                 .key("<Kafka API Key for confluent_kafka_cluster.basic-cluster>")
     *                 .secret("<Kafka API Secret for confluent_kafka_cluster.basic-cluster>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .topicName("orders")
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKafkaTopicResult> getKafkaTopicPlain(GetKafkaTopicPlainArgs args) {
        return getKafkaTopicPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaTopic` describes a Kafka Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .kafkaCluster(GetKafkaTopicKafkaClusterArgs.builder()
     *                 .id(basic_cluster.id())
     *                 .build())
     *             .topicName("orders")
     *             .restEndpoint(basic_cluster.restEndpoint())
     *             .credentials(GetKafkaTopicCredentialsArgs.builder()
     *                 .key("<Kafka API Key for confluent_kafka_cluster.basic-cluster>")
     *                 .secret("<Kafka API Secret for confluent_kafka_cluster.basic-cluster>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .topicName("orders")
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaTopicResult> getKafkaTopic(GetKafkaTopicArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKafkaTopic:getKafkaTopic", TypeShape.of(GetKafkaTopicResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaTopic` describes a Kafka Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .kafkaCluster(GetKafkaTopicKafkaClusterArgs.builder()
     *                 .id(basic_cluster.id())
     *                 .build())
     *             .topicName("orders")
     *             .restEndpoint(basic_cluster.restEndpoint())
     *             .credentials(GetKafkaTopicCredentialsArgs.builder()
     *                 .key("<Kafka API Key for confluent_kafka_cluster.basic-cluster>")
     *                 .secret("<Kafka API Secret for confluent_kafka_cluster.basic-cluster>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .topicName("orders")
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKafkaTopicResult> getKafkaTopic(GetKafkaTopicArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKafkaTopic:getKafkaTopic", TypeShape.of(GetKafkaTopicResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KafkaTopic` describes a Kafka Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Kafka clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .kafkaCluster(GetKafkaTopicKafkaClusterArgs.builder()
     *                 .id(basic_cluster.id())
     *                 .build())
     *             .topicName("orders")
     *             .restEndpoint(basic_cluster.restEndpoint())
     *             .credentials(GetKafkaTopicCredentialsArgs.builder()
     *                 .key("<Kafka API Key for confluent_kafka_cluster.basic-cluster>")
     *                 .secret("<Kafka API Secret for confluent_kafka_cluster.basic-cluster>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Kafka cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKafkaTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var orders = ConfluentcloudFunctions.getKafkaTopic(GetKafkaTopicArgs.builder()
     *             .topicName("orders")
     *             .build());
     * 
     *         ctx.export("config", orders.config());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKafkaTopicResult> getKafkaTopicPlain(GetKafkaTopicPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getKafkaTopic:getKafkaTopic", TypeShape.of(GetKafkaTopicResult.class), args, Utilities.withVersion(options));
    }
    /**
     * ## # confluentcloud.KsqlCluster Data Source
     * 
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KsqlCluster` describes a ksqlDB cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .id("lksqlc-abc123")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .displayName("ksqldb_cluster")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKsqlClusterResult> getKsqlCluster(GetKsqlClusterArgs args) {
        return getKsqlCluster(args, InvokeOptions.Empty);
    }
    /**
     * ## # confluentcloud.KsqlCluster Data Source
     * 
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KsqlCluster` describes a ksqlDB cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .id("lksqlc-abc123")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .displayName("ksqldb_cluster")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKsqlClusterResult> getKsqlClusterPlain(GetKsqlClusterPlainArgs args) {
        return getKsqlClusterPlain(args, InvokeOptions.Empty);
    }
    /**
     * ## # confluentcloud.KsqlCluster Data Source
     * 
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KsqlCluster` describes a ksqlDB cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .id("lksqlc-abc123")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .displayName("ksqldb_cluster")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKsqlClusterResult> getKsqlCluster(GetKsqlClusterArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKsqlCluster:getKsqlCluster", TypeShape.of(GetKsqlClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * ## # confluentcloud.KsqlCluster Data Source
     * 
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KsqlCluster` describes a ksqlDB cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .id("lksqlc-abc123")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .displayName("ksqldb_cluster")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetKsqlClusterResult> getKsqlCluster(GetKsqlClusterArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getKsqlCluster:getKsqlCluster", TypeShape.of(GetKsqlClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * ## # confluentcloud.KsqlCluster Data Source
     * 
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.KsqlCluster` describes a ksqlDB cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetKsqlClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .id("lksqlc-abc123")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getKsqlCluster(GetKsqlClusterArgs.builder()
     *             .displayName("ksqldb_cluster")
     *             .environment(GetKsqlClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetKsqlClusterResult> getKsqlClusterPlain(GetKsqlClusterPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getKsqlCluster:getKsqlCluster", TypeShape.of(GetKsqlClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .id("n-abc123")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .description(String.format("test_sa for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .displayName("my_network")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetNetworkResult> getNetwork(GetNetworkArgs args) {
        return getNetwork(args, InvokeOptions.Empty);
    }
    /**
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .id("n-abc123")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .description(String.format("test_sa for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .displayName("my_network")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetNetworkResult> getNetworkPlain(GetNetworkPlainArgs args) {
        return getNetworkPlain(args, InvokeOptions.Empty);
    }
    /**
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .id("n-abc123")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .description(String.format("test_sa for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .displayName("my_network")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetNetworkResult> getNetwork(GetNetworkArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getNetwork:getNetwork", TypeShape.of(GetNetworkResult.class), args, Utilities.withVersion(options));
    }
    /**
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .id("n-abc123")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .description(String.format("test_sa for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .displayName("my_network")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetNetworkResult> getNetwork(GetNetworkArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getNetwork:getNetwork", TypeShape.of(GetNetworkResult.class), args, Utilities.withVersion(options));
    }
    /**
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkEnvironmentArgs;
     * import com.pulumi.confluentcloud.ServiceAccount;
     * import com.pulumi.confluentcloud.ServiceAccountArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .id("n-abc123")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         var test_sa = new ServiceAccount("test-sa", ServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .description(String.format("test_sa for %s", exampleUsingId.displayName()))
     *             .build());
     * 
     *         final var exampleUsingName = ConfluentcloudFunctions.getNetwork(GetNetworkArgs.builder()
     *             .displayName("my_network")
     *             .environment(GetNetworkEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetNetworkResult> getNetworkPlain(GetNetworkPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getNetwork:getNetwork", TypeShape.of(GetNetworkResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkEndpoint` describes a Network Link Endpoint data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nle = ConfluentcloudFunctions.getNetworkLinkEndpoint(GetNetworkLinkEndpointArgs.builder()
     *             .id("nle-1357")
     *             .environment(GetNetworkLinkEndpointEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkEndpoint", nle);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetNetworkLinkEndpointResult> getNetworkLinkEndpoint(GetNetworkLinkEndpointArgs args) {
        return getNetworkLinkEndpoint(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkEndpoint` describes a Network Link Endpoint data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nle = ConfluentcloudFunctions.getNetworkLinkEndpoint(GetNetworkLinkEndpointArgs.builder()
     *             .id("nle-1357")
     *             .environment(GetNetworkLinkEndpointEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkEndpoint", nle);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetNetworkLinkEndpointResult> getNetworkLinkEndpointPlain(GetNetworkLinkEndpointPlainArgs args) {
        return getNetworkLinkEndpointPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkEndpoint` describes a Network Link Endpoint data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nle = ConfluentcloudFunctions.getNetworkLinkEndpoint(GetNetworkLinkEndpointArgs.builder()
     *             .id("nle-1357")
     *             .environment(GetNetworkLinkEndpointEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkEndpoint", nle);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetNetworkLinkEndpointResult> getNetworkLinkEndpoint(GetNetworkLinkEndpointArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getNetworkLinkEndpoint:getNetworkLinkEndpoint", TypeShape.of(GetNetworkLinkEndpointResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkEndpoint` describes a Network Link Endpoint data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nle = ConfluentcloudFunctions.getNetworkLinkEndpoint(GetNetworkLinkEndpointArgs.builder()
     *             .id("nle-1357")
     *             .environment(GetNetworkLinkEndpointEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkEndpoint", nle);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetNetworkLinkEndpointResult> getNetworkLinkEndpoint(GetNetworkLinkEndpointArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getNetworkLinkEndpoint:getNetworkLinkEndpoint", TypeShape.of(GetNetworkLinkEndpointResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkEndpoint` describes a Network Link Endpoint data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkEndpointEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nle = ConfluentcloudFunctions.getNetworkLinkEndpoint(GetNetworkLinkEndpointArgs.builder()
     *             .id("nle-1357")
     *             .environment(GetNetworkLinkEndpointEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkEndpoint", nle);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetNetworkLinkEndpointResult> getNetworkLinkEndpointPlain(GetNetworkLinkEndpointPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getNetworkLinkEndpoint:getNetworkLinkEndpoint", TypeShape.of(GetNetworkLinkEndpointResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkService` describes a Network Link Service data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nls = ConfluentcloudFunctions.getNetworkLinkService(GetNetworkLinkServiceArgs.builder()
     *             .id("nls-zyw30")
     *             .environment(GetNetworkLinkServiceEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkService", nls);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetNetworkLinkServiceResult> getNetworkLinkService(GetNetworkLinkServiceArgs args) {
        return getNetworkLinkService(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkService` describes a Network Link Service data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nls = ConfluentcloudFunctions.getNetworkLinkService(GetNetworkLinkServiceArgs.builder()
     *             .id("nls-zyw30")
     *             .environment(GetNetworkLinkServiceEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkService", nls);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetNetworkLinkServiceResult> getNetworkLinkServicePlain(GetNetworkLinkServicePlainArgs args) {
        return getNetworkLinkServicePlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkService` describes a Network Link Service data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nls = ConfluentcloudFunctions.getNetworkLinkService(GetNetworkLinkServiceArgs.builder()
     *             .id("nls-zyw30")
     *             .environment(GetNetworkLinkServiceEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkService", nls);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetNetworkLinkServiceResult> getNetworkLinkService(GetNetworkLinkServiceArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getNetworkLinkService:getNetworkLinkService", TypeShape.of(GetNetworkLinkServiceResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkService` describes a Network Link Service data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nls = ConfluentcloudFunctions.getNetworkLinkService(GetNetworkLinkServiceArgs.builder()
     *             .id("nls-zyw30")
     *             .environment(GetNetworkLinkServiceEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkService", nls);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetNetworkLinkServiceResult> getNetworkLinkService(GetNetworkLinkServiceArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getNetworkLinkService:getNetworkLinkService", TypeShape.of(GetNetworkLinkServiceResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.NetworkLinkService` describes a Network Link Service data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceArgs;
     * import com.pulumi.confluentcloud.inputs.GetNetworkLinkServiceEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var nls = ConfluentcloudFunctions.getNetworkLinkService(GetNetworkLinkServiceArgs.builder()
     *             .id("nls-zyw30")
     *             .environment(GetNetworkLinkServiceEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("networkLinkService", nls);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetNetworkLinkServiceResult> getNetworkLinkServicePlain(GetNetworkLinkServicePlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getNetworkLinkService:getNetworkLinkService", TypeShape.of(GetNetworkLinkServiceResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getOrganization` describes an Organization data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getOrganization(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetOrganizationResult> getOrganization() {
        return getOrganization(InvokeArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getOrganization` describes an Organization data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getOrganization(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetOrganizationResult> getOrganizationPlain() {
        return getOrganizationPlain(InvokeArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getOrganization` describes an Organization data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getOrganization(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetOrganizationResult> getOrganization(InvokeArgs args) {
        return getOrganization(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getOrganization` describes an Organization data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getOrganization(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetOrganizationResult> getOrganizationPlain(InvokeArgs args) {
        return getOrganizationPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getOrganization` describes an Organization data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getOrganization(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetOrganizationResult> getOrganization(InvokeArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getOrganization:getOrganization", TypeShape.of(GetOrganizationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getOrganization` describes an Organization data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getOrganization(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetOrganizationResult> getOrganization(InvokeArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getOrganization:getOrganization", TypeShape.of(GetOrganizationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getOrganization` describes an Organization data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getOrganization(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetOrganizationResult> getOrganizationPlain(InvokeArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getOrganization:getOrganization", TypeShape.of(GetOrganizationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Peering` describes a Peering data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPeeringArgs;
     * import com.pulumi.confluentcloud.inputs.GetPeeringEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .id("peer-abc123")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .displayName("my_peering")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetPeeringResult> getPeering(GetPeeringArgs args) {
        return getPeering(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Peering` describes a Peering data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPeeringArgs;
     * import com.pulumi.confluentcloud.inputs.GetPeeringEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .id("peer-abc123")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .displayName("my_peering")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetPeeringResult> getPeeringPlain(GetPeeringPlainArgs args) {
        return getPeeringPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Peering` describes a Peering data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPeeringArgs;
     * import com.pulumi.confluentcloud.inputs.GetPeeringEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .id("peer-abc123")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .displayName("my_peering")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetPeeringResult> getPeering(GetPeeringArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getPeering:getPeering", TypeShape.of(GetPeeringResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Peering` describes a Peering data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPeeringArgs;
     * import com.pulumi.confluentcloud.inputs.GetPeeringEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .id("peer-abc123")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .displayName("my_peering")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetPeeringResult> getPeering(GetPeeringArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getPeering:getPeering", TypeShape.of(GetPeeringResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Peering` describes a Peering data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPeeringArgs;
     * import com.pulumi.confluentcloud.inputs.GetPeeringEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .id("peer-abc123")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPeering(GetPeeringArgs.builder()
     *             .displayName("my_peering")
     *             .environment(GetPeeringEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetPeeringResult> getPeeringPlain(GetPeeringPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getPeering:getPeering", TypeShape.of(GetPeeringResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAccess` describes a Private Link Access data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .id("pla-abc123")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .displayName("my_pla")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetPrivateLinkAccessResult> getPrivateLinkAccess(GetPrivateLinkAccessArgs args) {
        return getPrivateLinkAccess(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAccess` describes a Private Link Access data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .id("pla-abc123")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .displayName("my_pla")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetPrivateLinkAccessResult> getPrivateLinkAccessPlain(GetPrivateLinkAccessPlainArgs args) {
        return getPrivateLinkAccessPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAccess` describes a Private Link Access data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .id("pla-abc123")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .displayName("my_pla")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetPrivateLinkAccessResult> getPrivateLinkAccess(GetPrivateLinkAccessArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getPrivateLinkAccess:getPrivateLinkAccess", TypeShape.of(GetPrivateLinkAccessResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAccess` describes a Private Link Access data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .id("pla-abc123")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .displayName("my_pla")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetPrivateLinkAccessResult> getPrivateLinkAccess(GetPrivateLinkAccessArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getPrivateLinkAccess:getPrivateLinkAccess", TypeShape.of(GetPrivateLinkAccessResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAccess` describes a Private Link Access data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAccessEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .id("pla-abc123")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getPrivateLinkAccess(GetPrivateLinkAccessArgs.builder()
     *             .displayName("my_pla")
     *             .environment(GetPrivateLinkAccessEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetPrivateLinkAccessResult> getPrivateLinkAccessPlain(GetPrivateLinkAccessPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getPrivateLinkAccess:getPrivateLinkAccess", TypeShape.of(GetPrivateLinkAccessResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachment` describes a Private Link Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachment(GetPrivateLinkAttachmentArgs.builder()
     *             .id("platt-abcde")
     *             .environment(GetPrivateLinkAttachmentEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("platt", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachment` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static Output<GetPrivateLinkAttachmentResult> getPrivateLinkAttachment(GetPrivateLinkAttachmentArgs args) {
        return getPrivateLinkAttachment(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachment` describes a Private Link Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachment(GetPrivateLinkAttachmentArgs.builder()
     *             .id("platt-abcde")
     *             .environment(GetPrivateLinkAttachmentEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("platt", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachment` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static CompletableFuture<GetPrivateLinkAttachmentResult> getPrivateLinkAttachmentPlain(GetPrivateLinkAttachmentPlainArgs args) {
        return getPrivateLinkAttachmentPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachment` describes a Private Link Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachment(GetPrivateLinkAttachmentArgs.builder()
     *             .id("platt-abcde")
     *             .environment(GetPrivateLinkAttachmentEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("platt", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachment` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static Output<GetPrivateLinkAttachmentResult> getPrivateLinkAttachment(GetPrivateLinkAttachmentArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getPrivateLinkAttachment:getPrivateLinkAttachment", TypeShape.of(GetPrivateLinkAttachmentResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachment` describes a Private Link Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachment(GetPrivateLinkAttachmentArgs.builder()
     *             .id("platt-abcde")
     *             .environment(GetPrivateLinkAttachmentEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("platt", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachment` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static Output<GetPrivateLinkAttachmentResult> getPrivateLinkAttachment(GetPrivateLinkAttachmentArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getPrivateLinkAttachment:getPrivateLinkAttachment", TypeShape.of(GetPrivateLinkAttachmentResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachment` describes a Private Link Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachment(GetPrivateLinkAttachmentArgs.builder()
     *             .id("platt-abcde")
     *             .environment(GetPrivateLinkAttachmentEnvironmentArgs.builder()
     *                 .id("env-1234")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("platt", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachment` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static CompletableFuture<GetPrivateLinkAttachmentResult> getPrivateLinkAttachmentPlain(GetPrivateLinkAttachmentPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getPrivateLinkAttachment:getPrivateLinkAttachment", TypeShape.of(GetPrivateLinkAttachmentResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachmentConnection` describes a Private Link Attachment Connection data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachmentConnection(GetPrivateLinkAttachmentConnectionArgs.builder()
     *             .id("plattc-p5j3ov")
     *             .environment(GetPrivateLinkAttachmentConnectionEnvironmentArgs.builder()
     *                 .id("env-8gv0v5")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("plattc", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachmentConnection` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static Output<GetPrivateLinkAttachmentConnectionResult> getPrivateLinkAttachmentConnection(GetPrivateLinkAttachmentConnectionArgs args) {
        return getPrivateLinkAttachmentConnection(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachmentConnection` describes a Private Link Attachment Connection data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachmentConnection(GetPrivateLinkAttachmentConnectionArgs.builder()
     *             .id("plattc-p5j3ov")
     *             .environment(GetPrivateLinkAttachmentConnectionEnvironmentArgs.builder()
     *                 .id("env-8gv0v5")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("plattc", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachmentConnection` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static CompletableFuture<GetPrivateLinkAttachmentConnectionResult> getPrivateLinkAttachmentConnectionPlain(GetPrivateLinkAttachmentConnectionPlainArgs args) {
        return getPrivateLinkAttachmentConnectionPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachmentConnection` describes a Private Link Attachment Connection data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachmentConnection(GetPrivateLinkAttachmentConnectionArgs.builder()
     *             .id("plattc-p5j3ov")
     *             .environment(GetPrivateLinkAttachmentConnectionEnvironmentArgs.builder()
     *                 .id("env-8gv0v5")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("plattc", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachmentConnection` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static Output<GetPrivateLinkAttachmentConnectionResult> getPrivateLinkAttachmentConnection(GetPrivateLinkAttachmentConnectionArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getPrivateLinkAttachmentConnection:getPrivateLinkAttachmentConnection", TypeShape.of(GetPrivateLinkAttachmentConnectionResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachmentConnection` describes a Private Link Attachment Connection data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachmentConnection(GetPrivateLinkAttachmentConnectionArgs.builder()
     *             .id("plattc-p5j3ov")
     *             .environment(GetPrivateLinkAttachmentConnectionEnvironmentArgs.builder()
     *                 .id("env-8gv0v5")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("plattc", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachmentConnection` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static Output<GetPrivateLinkAttachmentConnectionResult> getPrivateLinkAttachmentConnection(GetPrivateLinkAttachmentConnectionArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getPrivateLinkAttachmentConnection:getPrivateLinkAttachmentConnection", TypeShape.of(GetPrivateLinkAttachmentConnectionResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.PrivateLinkAttachmentConnection` describes a Private Link Attachment Connection data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionArgs;
     * import com.pulumi.confluentcloud.inputs.GetPrivateLinkAttachmentConnectionEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getPrivateLinkAttachmentConnection(GetPrivateLinkAttachmentConnectionArgs.builder()
     *             .id("plattc-p5j3ov")
     *             .environment(GetPrivateLinkAttachmentConnectionEnvironmentArgs.builder()
     *                 .id("env-8gv0v5")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("plattc", main);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.PrivateLinkAttachmentConnection` data source:
     * * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
     * * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
     * 
     */
    public static CompletableFuture<GetPrivateLinkAttachmentConnectionResult> getPrivateLinkAttachmentConnectionPlain(GetPrivateLinkAttachmentConnectionPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getPrivateLinkAttachmentConnection:getPrivateLinkAttachmentConnection", TypeShape.of(GetPrivateLinkAttachmentConnectionResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegration` describes a Confluent Provider Integration data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .id("cspi-4xg0q")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .displayName("provider_integration_main")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegration` data source:
     * * s3-sink-connector-assume-role: Amazon S3 Sink Connector with IAM role-based authorization using a Provider Integration
     * 
     */
    public static Output<GetProviderIntegrationResult> getProviderIntegration(GetProviderIntegrationArgs args) {
        return getProviderIntegration(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegration` describes a Confluent Provider Integration data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .id("cspi-4xg0q")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .displayName("provider_integration_main")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegration` data source:
     * * s3-sink-connector-assume-role: Amazon S3 Sink Connector with IAM role-based authorization using a Provider Integration
     * 
     */
    public static CompletableFuture<GetProviderIntegrationResult> getProviderIntegrationPlain(GetProviderIntegrationPlainArgs args) {
        return getProviderIntegrationPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegration` describes a Confluent Provider Integration data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .id("cspi-4xg0q")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .displayName("provider_integration_main")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegration` data source:
     * * s3-sink-connector-assume-role: Amazon S3 Sink Connector with IAM role-based authorization using a Provider Integration
     * 
     */
    public static Output<GetProviderIntegrationResult> getProviderIntegration(GetProviderIntegrationArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getProviderIntegration:getProviderIntegration", TypeShape.of(GetProviderIntegrationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegration` describes a Confluent Provider Integration data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .id("cspi-4xg0q")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .displayName("provider_integration_main")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegration` data source:
     * * s3-sink-connector-assume-role: Amazon S3 Sink Connector with IAM role-based authorization using a Provider Integration
     * 
     */
    public static Output<GetProviderIntegrationResult> getProviderIntegration(GetProviderIntegrationArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getProviderIntegration:getProviderIntegration", TypeShape.of(GetProviderIntegrationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegration` describes a Confluent Provider Integration data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .id("cspi-4xg0q")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getProviderIntegration(GetProviderIntegrationArgs.builder()
     *             .displayName("provider_integration_main")
     *             .environment(GetProviderIntegrationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegration` data source:
     * * s3-sink-connector-assume-role: Amazon S3 Sink Connector with IAM role-based authorization using a Provider Integration
     * 
     */
    public static CompletableFuture<GetProviderIntegrationResult> getProviderIntegrationPlain(GetProviderIntegrationPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getProviderIntegration:getProviderIntegration", TypeShape.of(GetProviderIntegrationResult.class), args, Utilities.withVersion(options));
    }
    public static Output<GetProviderIntegrationAuthorizationResult> getProviderIntegrationAuthorization(GetProviderIntegrationAuthorizationArgs args) {
        return getProviderIntegrationAuthorization(args, InvokeOptions.Empty);
    }
    public static CompletableFuture<GetProviderIntegrationAuthorizationResult> getProviderIntegrationAuthorizationPlain(GetProviderIntegrationAuthorizationPlainArgs args) {
        return getProviderIntegrationAuthorizationPlain(args, InvokeOptions.Empty);
    }
    public static Output<GetProviderIntegrationAuthorizationResult> getProviderIntegrationAuthorization(GetProviderIntegrationAuthorizationArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getProviderIntegrationAuthorization:getProviderIntegrationAuthorization", TypeShape.of(GetProviderIntegrationAuthorizationResult.class), args, Utilities.withVersion(options));
    }
    public static Output<GetProviderIntegrationAuthorizationResult> getProviderIntegrationAuthorization(GetProviderIntegrationAuthorizationArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getProviderIntegrationAuthorization:getProviderIntegrationAuthorization", TypeShape.of(GetProviderIntegrationAuthorizationResult.class), args, Utilities.withVersion(options));
    }
    public static CompletableFuture<GetProviderIntegrationAuthorizationResult> getProviderIntegrationAuthorizationPlain(GetProviderIntegrationAuthorizationPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getProviderIntegrationAuthorization:getProviderIntegrationAuthorization", TypeShape.of(GetProviderIntegrationAuthorizationResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegrationSetup` describes a Cloud Service Provider (CSP) integration that allows Confluent Cloud to access resources in your cloud provider account.
     * 
     * ## Example Usage
     * 
     * ### Azure Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azure = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("azureIntegrationStatus", azure.status());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### GCP Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var gcp = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .displayName("my-gcp-integration")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gcpIntegrationId", gcp.id());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Using with Authorization Resource
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         // Use the integration with authorization data source
     *         final var mainGetProviderIntegrationAuthorization = ConfluentcloudFunctions.getProviderIntegrationAuthorization(GetProviderIntegrationAuthorizationArgs.builder()
     *             .id(main.id())
     *             .environment(GetProviderIntegrationAuthorizationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegrationSetup` data source:
     * * provider-integration-azure: Complete Azure Provider Integration setup
     * * provider-integration-gcp: Complete GCP Provider Integration setup
     * 
     */
    public static Output<GetProviderIntegrationSetupResult> getProviderIntegrationSetup(GetProviderIntegrationSetupArgs args) {
        return getProviderIntegrationSetup(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegrationSetup` describes a Cloud Service Provider (CSP) integration that allows Confluent Cloud to access resources in your cloud provider account.
     * 
     * ## Example Usage
     * 
     * ### Azure Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azure = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("azureIntegrationStatus", azure.status());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### GCP Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var gcp = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .displayName("my-gcp-integration")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gcpIntegrationId", gcp.id());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Using with Authorization Resource
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         // Use the integration with authorization data source
     *         final var mainGetProviderIntegrationAuthorization = ConfluentcloudFunctions.getProviderIntegrationAuthorization(GetProviderIntegrationAuthorizationArgs.builder()
     *             .id(main.id())
     *             .environment(GetProviderIntegrationAuthorizationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegrationSetup` data source:
     * * provider-integration-azure: Complete Azure Provider Integration setup
     * * provider-integration-gcp: Complete GCP Provider Integration setup
     * 
     */
    public static CompletableFuture<GetProviderIntegrationSetupResult> getProviderIntegrationSetupPlain(GetProviderIntegrationSetupPlainArgs args) {
        return getProviderIntegrationSetupPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegrationSetup` describes a Cloud Service Provider (CSP) integration that allows Confluent Cloud to access resources in your cloud provider account.
     * 
     * ## Example Usage
     * 
     * ### Azure Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azure = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("azureIntegrationStatus", azure.status());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### GCP Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var gcp = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .displayName("my-gcp-integration")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gcpIntegrationId", gcp.id());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Using with Authorization Resource
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         // Use the integration with authorization data source
     *         final var mainGetProviderIntegrationAuthorization = ConfluentcloudFunctions.getProviderIntegrationAuthorization(GetProviderIntegrationAuthorizationArgs.builder()
     *             .id(main.id())
     *             .environment(GetProviderIntegrationAuthorizationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegrationSetup` data source:
     * * provider-integration-azure: Complete Azure Provider Integration setup
     * * provider-integration-gcp: Complete GCP Provider Integration setup
     * 
     */
    public static Output<GetProviderIntegrationSetupResult> getProviderIntegrationSetup(GetProviderIntegrationSetupArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getProviderIntegrationSetup:getProviderIntegrationSetup", TypeShape.of(GetProviderIntegrationSetupResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegrationSetup` describes a Cloud Service Provider (CSP) integration that allows Confluent Cloud to access resources in your cloud provider account.
     * 
     * ## Example Usage
     * 
     * ### Azure Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azure = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("azureIntegrationStatus", azure.status());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### GCP Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var gcp = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .displayName("my-gcp-integration")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gcpIntegrationId", gcp.id());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Using with Authorization Resource
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         // Use the integration with authorization data source
     *         final var mainGetProviderIntegrationAuthorization = ConfluentcloudFunctions.getProviderIntegrationAuthorization(GetProviderIntegrationAuthorizationArgs.builder()
     *             .id(main.id())
     *             .environment(GetProviderIntegrationAuthorizationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegrationSetup` data source:
     * * provider-integration-azure: Complete Azure Provider Integration setup
     * * provider-integration-gcp: Complete GCP Provider Integration setup
     * 
     */
    public static Output<GetProviderIntegrationSetupResult> getProviderIntegrationSetup(GetProviderIntegrationSetupArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getProviderIntegrationSetup:getProviderIntegrationSetup", TypeShape.of(GetProviderIntegrationSetupResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ProviderIntegrationSetup` describes a Cloud Service Provider (CSP) integration that allows Confluent Cloud to access resources in your cloud provider account.
     * 
     * ## Example Usage
     * 
     * ### Azure Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var azure = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("azureIntegrationStatus", azure.status());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### GCP Provider Integration
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var gcp = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .displayName("my-gcp-integration")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("gcpIntegrationId", gcp.id());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Using with Authorization Resource
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationSetupEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationArgs;
     * import com.pulumi.confluentcloud.inputs.GetProviderIntegrationAuthorizationEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getProviderIntegrationSetup(GetProviderIntegrationSetupArgs.builder()
     *             .id("cspi-abc123")
     *             .environment(GetProviderIntegrationSetupEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         // Use the integration with authorization data source
     *         final var mainGetProviderIntegrationAuthorization = ConfluentcloudFunctions.getProviderIntegrationAuthorization(GetProviderIntegrationAuthorizationArgs.builder()
     *             .id(main.id())
     *             .environment(GetProviderIntegrationAuthorizationEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ## Getting Started
     * 
     * The following end-to-end examples might help to get started with `confluentcloud.ProviderIntegrationSetup` data source:
     * * provider-integration-azure: Complete Azure Provider Integration setup
     * * provider-integration-gcp: Complete GCP Provider Integration setup
     * 
     */
    public static CompletableFuture<GetProviderIntegrationSetupResult> getProviderIntegrationSetupPlain(GetProviderIntegrationSetupPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getProviderIntegrationSetup:getProviderIntegrationSetup", TypeShape.of(GetProviderIntegrationSetupResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.RoleBinding` describes a Role Binding.
     * 
     * &gt; **Note:** For more information on the Role Bindings, see [Predefined RBAC roles in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/access-control/rbac/predefined-rbac-roles.html).
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetRoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getRoleBinding(GetRoleBindingArgs.builder()
     *             .id("rb-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetRoleBindingResult> getRoleBinding(GetRoleBindingArgs args) {
        return getRoleBinding(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.RoleBinding` describes a Role Binding.
     * 
     * &gt; **Note:** For more information on the Role Bindings, see [Predefined RBAC roles in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/access-control/rbac/predefined-rbac-roles.html).
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetRoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getRoleBinding(GetRoleBindingArgs.builder()
     *             .id("rb-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetRoleBindingResult> getRoleBindingPlain(GetRoleBindingPlainArgs args) {
        return getRoleBindingPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.RoleBinding` describes a Role Binding.
     * 
     * &gt; **Note:** For more information on the Role Bindings, see [Predefined RBAC roles in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/access-control/rbac/predefined-rbac-roles.html).
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetRoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getRoleBinding(GetRoleBindingArgs.builder()
     *             .id("rb-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetRoleBindingResult> getRoleBinding(GetRoleBindingArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getRoleBinding:getRoleBinding", TypeShape.of(GetRoleBindingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.RoleBinding` describes a Role Binding.
     * 
     * &gt; **Note:** For more information on the Role Bindings, see [Predefined RBAC roles in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/access-control/rbac/predefined-rbac-roles.html).
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetRoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getRoleBinding(GetRoleBindingArgs.builder()
     *             .id("rb-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetRoleBindingResult> getRoleBinding(GetRoleBindingArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getRoleBinding:getRoleBinding", TypeShape.of(GetRoleBindingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.RoleBinding` describes a Role Binding.
     * 
     * &gt; **Note:** For more information on the Role Bindings, see [Predefined RBAC roles in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/access-control/rbac/predefined-rbac-roles.html).
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetRoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getRoleBinding(GetRoleBindingArgs.builder()
     *             .id("rb-abc123")
     *             .build());
     * 
     *         ctx.export("example", example);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetRoleBindingResult> getRoleBindingPlain(GetRoleBindingPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getRoleBinding:getRoleBinding", TypeShape.of(GetRoleBindingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Schema` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .schemaRegistryCluster(GetSchemaSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .credentials(GetSchemaCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaResult> getSchema(GetSchemaArgs args) {
        return getSchema(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Schema` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .schemaRegistryCluster(GetSchemaSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .credentials(GetSchemaCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaResult> getSchemaPlain(GetSchemaPlainArgs args) {
        return getSchemaPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Schema` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .schemaRegistryCluster(GetSchemaSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .credentials(GetSchemaCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaResult> getSchema(GetSchemaArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchema:getSchema", TypeShape.of(GetSchemaResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Schema` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .schemaRegistryCluster(GetSchemaSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .credentials(GetSchemaCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaResult> getSchema(GetSchemaArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchema:getSchema", TypeShape.of(GetSchemaResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Schema` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .schemaRegistryCluster(GetSchemaSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .credentials(GetSchemaCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSchema(GetSchemaArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .schemaIdentifier(10001)
     *             .build());
     * 
     *         ctx.export("schema", purchase_v1.schema());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaResult> getSchemaPlain(GetSchemaPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSchema:getSchema", TypeShape.of(GetSchemaResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_cluster` describes a Schema Registry cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         // Loads the only Schema Registry cluster in the target environment
     *         final var exampleUsingEnvId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingEnvId", exampleUsingEnvId);
     *         final var exampleUsingId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .id("lsrc-abc123")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .displayName("Stream Governance Package")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterResult> getSchemaRegistryCluster(GetSchemaRegistryClusterArgs args) {
        return getSchemaRegistryCluster(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_cluster` describes a Schema Registry cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         // Loads the only Schema Registry cluster in the target environment
     *         final var exampleUsingEnvId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingEnvId", exampleUsingEnvId);
     *         final var exampleUsingId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .id("lsrc-abc123")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .displayName("Stream Governance Package")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClusterResult> getSchemaRegistryClusterPlain(GetSchemaRegistryClusterPlainArgs args) {
        return getSchemaRegistryClusterPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_cluster` describes a Schema Registry cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         // Loads the only Schema Registry cluster in the target environment
     *         final var exampleUsingEnvId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingEnvId", exampleUsingEnvId);
     *         final var exampleUsingId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .id("lsrc-abc123")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .displayName("Stream Governance Package")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterResult> getSchemaRegistryCluster(GetSchemaRegistryClusterArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryCluster:getSchemaRegistryCluster", TypeShape.of(GetSchemaRegistryClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_cluster` describes a Schema Registry cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         // Loads the only Schema Registry cluster in the target environment
     *         final var exampleUsingEnvId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingEnvId", exampleUsingEnvId);
     *         final var exampleUsingId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .id("lsrc-abc123")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .displayName("Stream Governance Package")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterResult> getSchemaRegistryCluster(GetSchemaRegistryClusterArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryCluster:getSchemaRegistryCluster", TypeShape.of(GetSchemaRegistryClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_cluster` describes a Schema Registry cluster data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         // Loads the only Schema Registry cluster in the target environment
     *         final var exampleUsingEnvId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingEnvId", exampleUsingEnvId);
     *         final var exampleUsingId = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .id("lsrc-abc123")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getSchemaRegistryCluster(GetSchemaRegistryClusterArgs.builder()
     *             .displayName("Stream Governance Package")
     *             .environment(GetSchemaRegistryClusterEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClusterResult> getSchemaRegistryClusterPlain(GetSchemaRegistryClusterPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSchemaRegistryCluster:getSchemaRegistryCluster", TypeShape.of(GetSchemaRegistryClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterConfig` describes a Schema Registry Cluster Config data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterConfigCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterConfigResult> getSchemaRegistryClusterConfig() {
        return getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterConfig` describes a Schema Registry Cluster Config data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterConfigCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClusterConfigResult> getSchemaRegistryClusterConfigPlain() {
        return getSchemaRegistryClusterConfigPlain(GetSchemaRegistryClusterConfigPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterConfig` describes a Schema Registry Cluster Config data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterConfigCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterConfigResult> getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs args) {
        return getSchemaRegistryClusterConfig(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterConfig` describes a Schema Registry Cluster Config data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterConfigCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClusterConfigResult> getSchemaRegistryClusterConfigPlain(GetSchemaRegistryClusterConfigPlainArgs args) {
        return getSchemaRegistryClusterConfigPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterConfig` describes a Schema Registry Cluster Config data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterConfigCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterConfigResult> getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryClusterConfig:getSchemaRegistryClusterConfig", TypeShape.of(GetSchemaRegistryClusterConfigResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterConfig` describes a Schema Registry Cluster Config data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterConfigCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterConfigResult> getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryClusterConfig:getSchemaRegistryClusterConfig", TypeShape.of(GetSchemaRegistryClusterConfigResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterConfig` describes a Schema Registry Cluster Config data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterConfigSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterConfigCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterConfigArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterConfig(GetSchemaRegistryClusterConfigArgs.builder()
     *             .build());
     * 
     *         ctx.export("compatibilityLevel", example.compatibilityLevel());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClusterConfigResult> getSchemaRegistryClusterConfigPlain(GetSchemaRegistryClusterConfigPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSchemaRegistryClusterConfig:getSchemaRegistryClusterConfig", TypeShape.of(GetSchemaRegistryClusterConfigResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterMode` describes a Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterModeResult> getSchemaRegistryClusterMode() {
        return getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterMode` describes a Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClusterModeResult> getSchemaRegistryClusterModePlain() {
        return getSchemaRegistryClusterModePlain(GetSchemaRegistryClusterModePlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterMode` describes a Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterModeResult> getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs args) {
        return getSchemaRegistryClusterMode(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterMode` describes a Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClusterModeResult> getSchemaRegistryClusterModePlain(GetSchemaRegistryClusterModePlainArgs args) {
        return getSchemaRegistryClusterModePlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterMode` describes a Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterModeResult> getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryClusterMode:getSchemaRegistryClusterMode", TypeShape.of(GetSchemaRegistryClusterModeResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterMode` describes a Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClusterModeResult> getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryClusterMode:getSchemaRegistryClusterMode", TypeShape.of(GetSchemaRegistryClusterModeResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryClusterMode` describes a Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryClusterModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryClusterModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClusterModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getSchemaRegistryClusterMode(GetSchemaRegistryClusterModeArgs.builder()
     *             .build());
     * 
     *         ctx.export("mode", example.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClusterModeResult> getSchemaRegistryClusterModePlain(GetSchemaRegistryClusterModePlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSchemaRegistryClusterMode:getSchemaRegistryClusterMode", TypeShape.of(GetSchemaRegistryClusterModeResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_clusters` describes a data source for Schema Registry Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemaRegistryClusters(GetSchemaRegistryClustersArgs.builder()
     *             .environment(GetSchemaRegistryClustersEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClustersResult> getSchemaRegistryClusters() {
        return getSchemaRegistryClusters(GetSchemaRegistryClustersArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_clusters` describes a data source for Schema Registry Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemaRegistryClusters(GetSchemaRegistryClustersArgs.builder()
     *             .environment(GetSchemaRegistryClustersEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClustersResult> getSchemaRegistryClustersPlain() {
        return getSchemaRegistryClustersPlain(GetSchemaRegistryClustersPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_clusters` describes a data source for Schema Registry Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemaRegistryClusters(GetSchemaRegistryClustersArgs.builder()
     *             .environment(GetSchemaRegistryClustersEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClustersResult> getSchemaRegistryClusters(GetSchemaRegistryClustersArgs args) {
        return getSchemaRegistryClusters(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_clusters` describes a data source for Schema Registry Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemaRegistryClusters(GetSchemaRegistryClustersArgs.builder()
     *             .environment(GetSchemaRegistryClustersEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClustersResult> getSchemaRegistryClustersPlain(GetSchemaRegistryClustersPlainArgs args) {
        return getSchemaRegistryClustersPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_clusters` describes a data source for Schema Registry Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemaRegistryClusters(GetSchemaRegistryClustersArgs.builder()
     *             .environment(GetSchemaRegistryClustersEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClustersResult> getSchemaRegistryClusters(GetSchemaRegistryClustersArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryClusters:getSchemaRegistryClusters", TypeShape.of(GetSchemaRegistryClustersResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_clusters` describes a data source for Schema Registry Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemaRegistryClusters(GetSchemaRegistryClustersArgs.builder()
     *             .environment(GetSchemaRegistryClustersEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryClustersResult> getSchemaRegistryClusters(GetSchemaRegistryClustersArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryClusters:getSchemaRegistryClusters", TypeShape.of(GetSchemaRegistryClustersResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `data.confluent_schema_registry_clusters` describes a data source for Schema Registry Clusters.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryClustersEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemaRegistryClusters(GetSchemaRegistryClustersArgs.builder()
     *             .environment(GetSchemaRegistryClustersEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryClustersResult> getSchemaRegistryClustersPlain(GetSchemaRegistryClustersPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSchemaRegistryClusters:getSchemaRegistryClusters", TypeShape.of(GetSchemaRegistryClustersResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryDek` describes a Schema Registry Data Encryption Key (DEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryDekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryDekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryDekResult> getSchemaRegistryDek(GetSchemaRegistryDekArgs args) {
        return getSchemaRegistryDek(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryDek` describes a Schema Registry Data Encryption Key (DEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryDekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryDekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryDekResult> getSchemaRegistryDekPlain(GetSchemaRegistryDekPlainArgs args) {
        return getSchemaRegistryDekPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryDek` describes a Schema Registry Data Encryption Key (DEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryDekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryDekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryDekResult> getSchemaRegistryDek(GetSchemaRegistryDekArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryDek:getSchemaRegistryDek", TypeShape.of(GetSchemaRegistryDekResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryDek` describes a Schema Registry Data Encryption Key (DEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryDekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryDekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryDekResult> getSchemaRegistryDek(GetSchemaRegistryDekArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryDek:getSchemaRegistryDek", TypeShape.of(GetSchemaRegistryDekResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryDek` describes a Schema Registry Data Encryption Key (DEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryDekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryDekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryDekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryDek(GetSchemaRegistryDekArgs.builder()
     *             .kekName("my_kek")
     *             .subjectName("my_subject")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryDekResult> getSchemaRegistryDekPlain(GetSchemaRegistryDekPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSchemaRegistryDek:getSchemaRegistryDek", TypeShape.of(GetSchemaRegistryDekResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryKek` describes a Schema Registry Key Encryption Key (KEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryKekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryKekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryKekResult> getSchemaRegistryKek(GetSchemaRegistryKekArgs args) {
        return getSchemaRegistryKek(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryKek` describes a Schema Registry Key Encryption Key (KEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryKekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryKekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryKekResult> getSchemaRegistryKekPlain(GetSchemaRegistryKekPlainArgs args) {
        return getSchemaRegistryKekPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryKek` describes a Schema Registry Key Encryption Key (KEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryKekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryKekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryKekResult> getSchemaRegistryKek(GetSchemaRegistryKekArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryKek:getSchemaRegistryKek", TypeShape.of(GetSchemaRegistryKekResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryKek` describes a Schema Registry Key Encryption Key (KEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryKekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryKekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemaRegistryKekResult> getSchemaRegistryKek(GetSchemaRegistryKekArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemaRegistryKek:getSchemaRegistryKek", TypeShape.of(GetSchemaRegistryKekResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SchemaRegistryKek` describes a Schema Registry Key Encryption Key (KEK) data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .schemaRegistryCluster(GetSchemaRegistryKekSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetSchemaRegistryKekCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemaRegistryKekArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var myKey = ConfluentcloudFunctions.getSchemaRegistryKek(GetSchemaRegistryKekArgs.builder()
     *             .name("my_key")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemaRegistryKekResult> getSchemaRegistryKekPlain(GetSchemaRegistryKekPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSchemaRegistryKek:getSchemaRegistryKek", TypeShape.of(GetSchemaRegistryKekResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getSchemas` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .schemaRegistryCluster(GetSchemasSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .credentials(GetSchemasCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemasResult> getSchemas() {
        return getSchemas(GetSchemasArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getSchemas` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .schemaRegistryCluster(GetSchemasSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .credentials(GetSchemasCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemasResult> getSchemasPlain() {
        return getSchemasPlain(GetSchemasPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getSchemas` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .schemaRegistryCluster(GetSchemasSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .credentials(GetSchemasCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemasResult> getSchemas(GetSchemasArgs args) {
        return getSchemas(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getSchemas` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .schemaRegistryCluster(GetSchemasSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .credentials(GetSchemasCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemasResult> getSchemasPlain(GetSchemasPlainArgs args) {
        return getSchemasPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getSchemas` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .schemaRegistryCluster(GetSchemasSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .credentials(GetSchemasCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemasResult> getSchemas(GetSchemasArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemas:getSchemas", TypeShape.of(GetSchemasResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getSchemas` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .schemaRegistryCluster(GetSchemasSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .credentials(GetSchemasCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSchemasResult> getSchemas(GetSchemasArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSchemas:getSchemas", TypeShape.of(GetSchemasResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getSchemas` describes a Schema data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .schemaRegistryCluster(GetSchemasSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .credentials(GetSchemasCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSchemasArgs;
     * import com.pulumi.confluentcloud.inputs.GetSchemasFilterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getSchemas(GetSchemasArgs.builder()
     *             .filter(GetSchemasFilterArgs.builder()
     *                 .subjectPrefix("examples.record")
     *                 .latestOnly(false)
     *                 .deleted(true)
     *                 .build())
     *             .build());
     * 
     *         ctx.export("schemas", main.schemas());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSchemasResult> getSchemasPlain(GetSchemasPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSchemas:getSchemas", TypeShape.of(GetSchemasResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ServiceAccount` describes a Service Account data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .id("sa-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.displayName()))
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetServiceAccountResult> getServiceAccount() {
        return getServiceAccount(GetServiceAccountArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ServiceAccount` describes a Service Account data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .id("sa-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.displayName()))
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetServiceAccountResult> getServiceAccountPlain() {
        return getServiceAccountPlain(GetServiceAccountPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ServiceAccount` describes a Service Account data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .id("sa-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.displayName()))
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetServiceAccountResult> getServiceAccount(GetServiceAccountArgs args) {
        return getServiceAccount(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ServiceAccount` describes a Service Account data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .id("sa-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.displayName()))
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetServiceAccountResult> getServiceAccountPlain(GetServiceAccountPlainArgs args) {
        return getServiceAccountPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ServiceAccount` describes a Service Account data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .id("sa-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.displayName()))
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetServiceAccountResult> getServiceAccount(GetServiceAccountArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getServiceAccount:getServiceAccount", TypeShape.of(GetServiceAccountResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ServiceAccount` describes a Service Account data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .id("sa-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.displayName()))
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetServiceAccountResult> getServiceAccount(GetServiceAccountArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getServiceAccount:getServiceAccount", TypeShape.of(GetServiceAccountResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.ServiceAccount` describes a Service Account data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetServiceAccountArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .id("sa-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getServiceAccount(GetServiceAccountArgs.builder()
     *             .displayName("test_sa")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.displayName()))
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetServiceAccountResult> getServiceAccountPlain(GetServiceAccountPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getServiceAccount:getServiceAccount", TypeShape.of(GetServiceAccountResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentSubjectCompatibilityLevel` describes a Subject Config data source.
     * 
     * ## Example Usage
     * 
     */
    public static Output<GetSubjectConfigResult> getSubjectConfig(GetSubjectConfigArgs args) {
        return getSubjectConfig(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentSubjectCompatibilityLevel` describes a Subject Config data source.
     * 
     * ## Example Usage
     * 
     */
    public static CompletableFuture<GetSubjectConfigResult> getSubjectConfigPlain(GetSubjectConfigPlainArgs args) {
        return getSubjectConfigPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentSubjectCompatibilityLevel` describes a Subject Config data source.
     * 
     * ## Example Usage
     * 
     */
    public static Output<GetSubjectConfigResult> getSubjectConfig(GetSubjectConfigArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSubjectConfig:getSubjectConfig", TypeShape.of(GetSubjectConfigResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentSubjectCompatibilityLevel` describes a Subject Config data source.
     * 
     * ## Example Usage
     * 
     */
    public static Output<GetSubjectConfigResult> getSubjectConfig(GetSubjectConfigArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSubjectConfig:getSubjectConfig", TypeShape.of(GetSubjectConfigResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentSubjectCompatibilityLevel` describes a Subject Config data source.
     * 
     * ## Example Usage
     * 
     */
    public static CompletableFuture<GetSubjectConfigResult> getSubjectConfigPlain(GetSubjectConfigPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSubjectConfig:getSubjectConfig", TypeShape.of(GetSubjectConfigResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SubjectMode` describes a Subject Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .schemaRegistryCluster(GetSubjectModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .credentials(GetSubjectModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSubjectModeResult> getSubjectMode(GetSubjectModeArgs args) {
        return getSubjectMode(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SubjectMode` describes a Subject Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .schemaRegistryCluster(GetSubjectModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .credentials(GetSubjectModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSubjectModeResult> getSubjectModePlain(GetSubjectModePlainArgs args) {
        return getSubjectModePlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SubjectMode` describes a Subject Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .schemaRegistryCluster(GetSubjectModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .credentials(GetSubjectModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSubjectModeResult> getSubjectMode(GetSubjectModeArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSubjectMode:getSubjectMode", TypeShape.of(GetSubjectModeResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SubjectMode` describes a Subject Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .schemaRegistryCluster(GetSubjectModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .credentials(GetSubjectModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSubjectModeResult> getSubjectMode(GetSubjectModeArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getSubjectMode:getSubjectMode", TypeShape.of(GetSubjectModeResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.SubjectMode` describes a Subject Mode data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .schemaRegistryCluster(GetSubjectModeSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .subjectName("proto-purchase-value")
     *             .credentials(GetSubjectModeCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetSubjectModeArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var purchase-v1 = ConfluentcloudFunctions.getSubjectMode(GetSubjectModeArgs.builder()
     *             .subjectName("proto-purchase-value")
     *             .build());
     * 
     *         ctx.export("mode", purchase_v1.mode());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSubjectModeResult> getSubjectModePlain(GetSubjectModePlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getSubjectMode:getSubjectMode", TypeShape.of(GetSubjectModeResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TableflowTopic` describes a Tableflow Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Tableflow Topics in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .environment(GetTableflowTopicEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetTableflowTopicKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .displayName("tableflow-example")
     *             .credentials(GetTableflowTopicCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Tableflow Topic in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .displayName("tableflow-example")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetTableflowTopicResult> getTableflowTopic(GetTableflowTopicArgs args) {
        return getTableflowTopic(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TableflowTopic` describes a Tableflow Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Tableflow Topics in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .environment(GetTableflowTopicEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetTableflowTopicKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .displayName("tableflow-example")
     *             .credentials(GetTableflowTopicCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Tableflow Topic in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .displayName("tableflow-example")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetTableflowTopicResult> getTableflowTopicPlain(GetTableflowTopicPlainArgs args) {
        return getTableflowTopicPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TableflowTopic` describes a Tableflow Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Tableflow Topics in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .environment(GetTableflowTopicEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetTableflowTopicKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .displayName("tableflow-example")
     *             .credentials(GetTableflowTopicCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Tableflow Topic in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .displayName("tableflow-example")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetTableflowTopicResult> getTableflowTopic(GetTableflowTopicArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getTableflowTopic:getTableflowTopic", TypeShape.of(GetTableflowTopicResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TableflowTopic` describes a Tableflow Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Tableflow Topics in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .environment(GetTableflowTopicEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetTableflowTopicKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .displayName("tableflow-example")
     *             .credentials(GetTableflowTopicCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Tableflow Topic in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .displayName("tableflow-example")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetTableflowTopicResult> getTableflowTopic(GetTableflowTopicArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getTableflowTopic:getTableflowTopic", TypeShape.of(GetTableflowTopicResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TableflowTopic` describes a Tableflow Topic data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Tableflow Topics in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicEnvironmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicKafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .environment(GetTableflowTopicEnvironmentArgs.builder()
     *                 .id(staging.id())
     *                 .build())
     *             .kafkaCluster(GetTableflowTopicKafkaClusterArgs.builder()
     *                 .id(stagingConfluentKafkaCluster.id())
     *                 .build())
     *             .displayName("tableflow-example")
     *             .credentials(GetTableflowTopicCredentialsArgs.builder()
     *                 .key(env_admin_tableflow_api_key.id())
     *                 .secret(env_admin_tableflow_api_key.secret())
     *                 .build())
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Tableflow Topic in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTableflowTopicArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = ConfluentcloudFunctions.getTableflowTopic(GetTableflowTopicArgs.builder()
     *             .displayName("tableflow-example")
     *             .build());
     * 
     *         ctx.export("retention-ms", example.retentionMs());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetTableflowTopicResult> getTableflowTopicPlain(GetTableflowTopicPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getTableflowTopic:getTableflowTopic", TypeShape.of(GetTableflowTopicResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Tag` describes a Tag data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .schemaRegistryCluster(GetTagSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetTagResult> getTag(GetTagArgs args) {
        return getTag(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Tag` describes a Tag data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .schemaRegistryCluster(GetTagSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static CompletableFuture<GetTagResult> getTagPlain(GetTagPlainArgs args) {
        return getTagPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Tag` describes a Tag data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .schemaRegistryCluster(GetTagSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetTagResult> getTag(GetTagArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getTag:getTag", TypeShape.of(GetTagResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Tag` describes a Tag data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .schemaRegistryCluster(GetTagSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetTagResult> getTag(GetTagArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getTag:getTag", TypeShape.of(GetTagResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.Tag` describes a Tag data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .schemaRegistryCluster(GetTagSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var pii = ConfluentcloudFunctions.getTag(GetTagArgs.builder()
     *             .name("PII")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static CompletableFuture<GetTagResult> getTagPlain(GetTagPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getTag:getTag", TypeShape.of(GetTagResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TagBinding` describes a Tag Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .schemaRegistryCluster(GetTagBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetTagBindingResult> getTagBinding(GetTagBindingArgs args) {
        return getTagBinding(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TagBinding` describes a Tag Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .schemaRegistryCluster(GetTagBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static CompletableFuture<GetTagBindingResult> getTagBindingPlain(GetTagBindingPlainArgs args) {
        return getTagBindingPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TagBinding` describes a Tag Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .schemaRegistryCluster(GetTagBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetTagBindingResult> getTagBinding(GetTagBindingArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getTagBinding:getTagBinding", TypeShape.of(GetTagBindingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TagBinding` describes a Tag Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .schemaRegistryCluster(GetTagBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static Output<GetTagBindingResult> getTagBinding(GetTagBindingArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getTagBinding:getTagBinding", TypeShape.of(GetTagBindingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TagBinding` describes a Tag Binding data source.
     * 
     * ## Example Usage
     * 
     * ### Option #1: Manage multiple Schema Registry clusters in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingSchemaRegistryClusterArgs;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .schemaRegistryCluster(GetTagBindingSchemaRegistryClusterArgs.builder()
     *                 .id(essentials.id())
     *                 .build())
     *             .restEndpoint(essentials.restEndpoint())
     *             .credentials(GetTagBindingCredentialsArgs.builder()
     *                 .key("<Schema Registry API Key for data.confluent_schema_registry_cluster.essentials>")
     *                 .secret("<Schema Registry API Secret for data.confluent_schema_registry_cluster.essentials>")
     *                 .build())
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     * ### Option #2: Manage a single Schema Registry cluster in the same Pulumi Stack
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTagBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getTagBinding(GetTagBindingArgs.builder()
     *             .tagName("PII")
     *             .entityName("lsrc-8wrx70:.:100001")
     *             .entityType("sr_schema")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * &gt; **Note:** We also support `schemaRegistryRestEndpoint` instead of `catalogRestEndpoint` for the time being.
     * 
     */
    public static CompletableFuture<GetTagBindingResult> getTagBindingPlain(GetTagBindingPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getTagBinding:getTagBinding", TypeShape.of(GetTagBindingResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TransitGatewayAttachment` describes a Transit Gateway Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .id("tgwa-abc123")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .displayName("my_tgwa")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetTransitGatewayAttachmentResult> getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs args) {
        return getTransitGatewayAttachment(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TransitGatewayAttachment` describes a Transit Gateway Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .id("tgwa-abc123")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .displayName("my_tgwa")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetTransitGatewayAttachmentResult> getTransitGatewayAttachmentPlain(GetTransitGatewayAttachmentPlainArgs args) {
        return getTransitGatewayAttachmentPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TransitGatewayAttachment` describes a Transit Gateway Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .id("tgwa-abc123")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .displayName("my_tgwa")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetTransitGatewayAttachmentResult> getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getTransitGatewayAttachment:getTransitGatewayAttachment", TypeShape.of(GetTransitGatewayAttachmentResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TransitGatewayAttachment` describes a Transit Gateway Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .id("tgwa-abc123")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .displayName("my_tgwa")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetTransitGatewayAttachmentResult> getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getTransitGatewayAttachment:getTransitGatewayAttachment", TypeShape.of(GetTransitGatewayAttachmentResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.TransitGatewayAttachment` describes a Transit Gateway Attachment data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentArgs;
     * import com.pulumi.confluentcloud.inputs.GetTransitGatewayAttachmentEnvironmentArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var exampleUsingId = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .id("tgwa-abc123")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingName = ConfluentcloudFunctions.getTransitGatewayAttachment(GetTransitGatewayAttachmentArgs.builder()
     *             .displayName("my_tgwa")
     *             .environment(GetTransitGatewayAttachmentEnvironmentArgs.builder()
     *                 .id("env-xyz456")
     *                 .build())
     *             .build());
     * 
     *         ctx.export("exampleUsingName", exampleUsingName);
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetTransitGatewayAttachmentResult> getTransitGatewayAttachmentPlain(GetTransitGatewayAttachmentPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getTransitGatewayAttachment:getTransitGatewayAttachment", TypeShape.of(GetTransitGatewayAttachmentResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUser` describes a User data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetUserArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import com.pulumi.confluentcloud.KafkaCluster;
     * import com.pulumi.confluentcloud.KafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterStandardArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App }{{@code
     *     public static void main(String[] args) }{{@code
     *         Pulumi.run(App::stack);
     *     }}{@code
     * 
     *     public static void stack(Context ctx) }{{@code
     *         final var exampleUsingId = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .id("u-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingEmail = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .email("test123}{@literal @}{@code gmail.com")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.fullName()))
     *             .build());
     * 
     *         var standard_cluster_on_aws = new KafkaCluster("standard-cluster-on-aws", KafkaClusterArgs.builder()
     *             .displayName("standard_kafka_cluster_on_aws")
     *             .availability("SINGLE_ZONE")
     *             .cloud("AWS")
     *             .region("us-west-2")
     *             .standard(KafkaClusterStandardArgs.builder()
     *                 .build())
     *             .environment(KafkaClusterEnvironmentArgs.builder()
     *                 .id(test_env.id())
     *                 .build())
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingEmail.id()))
     *             .roleName("CloudClusterAdmin")
     *             .crnPattern(standard_cluster_on_aws.rbacCrn())
     *             .build());
     * 
     *         final var exampleUsingFullName = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .fullName("John Doe")
     *             .build());
     * 
     *     }}{@code
     * }}{@code
     * }
     * </pre>
     * 
     */
    public static Output<GetUserResult> getUser() {
        return getUser(GetUserArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUser` describes a User data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetUserArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import com.pulumi.confluentcloud.KafkaCluster;
     * import com.pulumi.confluentcloud.KafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterStandardArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App }{{@code
     *     public static void main(String[] args) }{{@code
     *         Pulumi.run(App::stack);
     *     }}{@code
     * 
     *     public static void stack(Context ctx) }{{@code
     *         final var exampleUsingId = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .id("u-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingEmail = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .email("test123}{@literal @}{@code gmail.com")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.fullName()))
     *             .build());
     * 
     *         var standard_cluster_on_aws = new KafkaCluster("standard-cluster-on-aws", KafkaClusterArgs.builder()
     *             .displayName("standard_kafka_cluster_on_aws")
     *             .availability("SINGLE_ZONE")
     *             .cloud("AWS")
     *             .region("us-west-2")
     *             .standard(KafkaClusterStandardArgs.builder()
     *                 .build())
     *             .environment(KafkaClusterEnvironmentArgs.builder()
     *                 .id(test_env.id())
     *                 .build())
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingEmail.id()))
     *             .roleName("CloudClusterAdmin")
     *             .crnPattern(standard_cluster_on_aws.rbacCrn())
     *             .build());
     * 
     *         final var exampleUsingFullName = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .fullName("John Doe")
     *             .build());
     * 
     *     }}{@code
     * }}{@code
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetUserResult> getUserPlain() {
        return getUserPlain(GetUserPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUser` describes a User data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetUserArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import com.pulumi.confluentcloud.KafkaCluster;
     * import com.pulumi.confluentcloud.KafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterStandardArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App }{{@code
     *     public static void main(String[] args) }{{@code
     *         Pulumi.run(App::stack);
     *     }}{@code
     * 
     *     public static void stack(Context ctx) }{{@code
     *         final var exampleUsingId = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .id("u-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingEmail = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .email("test123}{@literal @}{@code gmail.com")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.fullName()))
     *             .build());
     * 
     *         var standard_cluster_on_aws = new KafkaCluster("standard-cluster-on-aws", KafkaClusterArgs.builder()
     *             .displayName("standard_kafka_cluster_on_aws")
     *             .availability("SINGLE_ZONE")
     *             .cloud("AWS")
     *             .region("us-west-2")
     *             .standard(KafkaClusterStandardArgs.builder()
     *                 .build())
     *             .environment(KafkaClusterEnvironmentArgs.builder()
     *                 .id(test_env.id())
     *                 .build())
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingEmail.id()))
     *             .roleName("CloudClusterAdmin")
     *             .crnPattern(standard_cluster_on_aws.rbacCrn())
     *             .build());
     * 
     *         final var exampleUsingFullName = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .fullName("John Doe")
     *             .build());
     * 
     *     }}{@code
     * }}{@code
     * }
     * </pre>
     * 
     */
    public static Output<GetUserResult> getUser(GetUserArgs args) {
        return getUser(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUser` describes a User data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetUserArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import com.pulumi.confluentcloud.KafkaCluster;
     * import com.pulumi.confluentcloud.KafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterStandardArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App }{{@code
     *     public static void main(String[] args) }{{@code
     *         Pulumi.run(App::stack);
     *     }}{@code
     * 
     *     public static void stack(Context ctx) }{{@code
     *         final var exampleUsingId = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .id("u-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingEmail = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .email("test123}{@literal @}{@code gmail.com")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.fullName()))
     *             .build());
     * 
     *         var standard_cluster_on_aws = new KafkaCluster("standard-cluster-on-aws", KafkaClusterArgs.builder()
     *             .displayName("standard_kafka_cluster_on_aws")
     *             .availability("SINGLE_ZONE")
     *             .cloud("AWS")
     *             .region("us-west-2")
     *             .standard(KafkaClusterStandardArgs.builder()
     *                 .build())
     *             .environment(KafkaClusterEnvironmentArgs.builder()
     *                 .id(test_env.id())
     *                 .build())
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingEmail.id()))
     *             .roleName("CloudClusterAdmin")
     *             .crnPattern(standard_cluster_on_aws.rbacCrn())
     *             .build());
     * 
     *         final var exampleUsingFullName = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .fullName("John Doe")
     *             .build());
     * 
     *     }}{@code
     * }}{@code
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetUserResult> getUserPlain(GetUserPlainArgs args) {
        return getUserPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUser` describes a User data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetUserArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import com.pulumi.confluentcloud.KafkaCluster;
     * import com.pulumi.confluentcloud.KafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterStandardArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App }{{@code
     *     public static void main(String[] args) }{{@code
     *         Pulumi.run(App::stack);
     *     }}{@code
     * 
     *     public static void stack(Context ctx) }{{@code
     *         final var exampleUsingId = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .id("u-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingEmail = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .email("test123}{@literal @}{@code gmail.com")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.fullName()))
     *             .build());
     * 
     *         var standard_cluster_on_aws = new KafkaCluster("standard-cluster-on-aws", KafkaClusterArgs.builder()
     *             .displayName("standard_kafka_cluster_on_aws")
     *             .availability("SINGLE_ZONE")
     *             .cloud("AWS")
     *             .region("us-west-2")
     *             .standard(KafkaClusterStandardArgs.builder()
     *                 .build())
     *             .environment(KafkaClusterEnvironmentArgs.builder()
     *                 .id(test_env.id())
     *                 .build())
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingEmail.id()))
     *             .roleName("CloudClusterAdmin")
     *             .crnPattern(standard_cluster_on_aws.rbacCrn())
     *             .build());
     * 
     *         final var exampleUsingFullName = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .fullName("John Doe")
     *             .build());
     * 
     *     }}{@code
     * }}{@code
     * }
     * </pre>
     * 
     */
    public static Output<GetUserResult> getUser(GetUserArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getUser:getUser", TypeShape.of(GetUserResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUser` describes a User data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetUserArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import com.pulumi.confluentcloud.KafkaCluster;
     * import com.pulumi.confluentcloud.KafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterStandardArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App }{{@code
     *     public static void main(String[] args) }{{@code
     *         Pulumi.run(App::stack);
     *     }}{@code
     * 
     *     public static void stack(Context ctx) }{{@code
     *         final var exampleUsingId = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .id("u-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingEmail = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .email("test123}{@literal @}{@code gmail.com")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.fullName()))
     *             .build());
     * 
     *         var standard_cluster_on_aws = new KafkaCluster("standard-cluster-on-aws", KafkaClusterArgs.builder()
     *             .displayName("standard_kafka_cluster_on_aws")
     *             .availability("SINGLE_ZONE")
     *             .cloud("AWS")
     *             .region("us-west-2")
     *             .standard(KafkaClusterStandardArgs.builder()
     *                 .build())
     *             .environment(KafkaClusterEnvironmentArgs.builder()
     *                 .id(test_env.id())
     *                 .build())
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingEmail.id()))
     *             .roleName("CloudClusterAdmin")
     *             .crnPattern(standard_cluster_on_aws.rbacCrn())
     *             .build());
     * 
     *         final var exampleUsingFullName = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .fullName("John Doe")
     *             .build());
     * 
     *     }}{@code
     * }}{@code
     * }
     * </pre>
     * 
     */
    public static Output<GetUserResult> getUser(GetUserArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getUser:getUser", TypeShape.of(GetUserResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUser` describes a User data source.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import com.pulumi.confluentcloud.inputs.GetUserArgs;
     * import com.pulumi.confluentcloud.Environment;
     * import com.pulumi.confluentcloud.EnvironmentArgs;
     * import com.pulumi.confluentcloud.KafkaCluster;
     * import com.pulumi.confluentcloud.KafkaClusterArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterStandardArgs;
     * import com.pulumi.confluentcloud.inputs.KafkaClusterEnvironmentArgs;
     * import com.pulumi.confluentcloud.RoleBinding;
     * import com.pulumi.confluentcloud.RoleBindingArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App }{{@code
     *     public static void main(String[] args) }{{@code
     *         Pulumi.run(App::stack);
     *     }}{@code
     * 
     *     public static void stack(Context ctx) }{{@code
     *         final var exampleUsingId = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .id("u-abc123")
     *             .build());
     * 
     *         ctx.export("exampleUsingId", exampleUsingId);
     *         final var exampleUsingEmail = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .email("test123}{@literal @}{@code gmail.com")
     *             .build());
     * 
     *         var test_env = new Environment("test-env", EnvironmentArgs.builder()
     *             .displayName(String.format("env_for_%s", exampleUsingId.fullName()))
     *             .build());
     * 
     *         var standard_cluster_on_aws = new KafkaCluster("standard-cluster-on-aws", KafkaClusterArgs.builder()
     *             .displayName("standard_kafka_cluster_on_aws")
     *             .availability("SINGLE_ZONE")
     *             .cloud("AWS")
     *             .region("us-west-2")
     *             .standard(KafkaClusterStandardArgs.builder()
     *                 .build())
     *             .environment(KafkaClusterEnvironmentArgs.builder()
     *                 .id(test_env.id())
     *                 .build())
     *             .build());
     * 
     *         var test_role_binding = new RoleBinding("test-role-binding", RoleBindingArgs.builder()
     *             .principal(String.format("User:%s", exampleUsingEmail.id()))
     *             .roleName("CloudClusterAdmin")
     *             .crnPattern(standard_cluster_on_aws.rbacCrn())
     *             .build());
     * 
     *         final var exampleUsingFullName = ConfluentcloudFunctions.getUser(GetUserArgs.builder()
     *             .fullName("John Doe")
     *             .build());
     * 
     *     }}{@code
     * }}{@code
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetUserResult> getUserPlain(GetUserPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getUser:getUser", TypeShape.of(GetUserResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUsers` describes a data source for Users.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getUsers(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("users", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetUsersResult> getUsers() {
        return getUsers(InvokeArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUsers` describes a data source for Users.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getUsers(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("users", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetUsersResult> getUsersPlain() {
        return getUsersPlain(InvokeArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUsers` describes a data source for Users.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getUsers(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("users", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetUsersResult> getUsers(InvokeArgs args) {
        return getUsers(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUsers` describes a data source for Users.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getUsers(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("users", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetUsersResult> getUsersPlain(InvokeArgs args) {
        return getUsersPlain(args, InvokeOptions.Empty);
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUsers` describes a data source for Users.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getUsers(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("users", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetUsersResult> getUsers(InvokeArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getUsers:getUsers", TypeShape.of(GetUsersResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUsers` describes a data source for Users.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getUsers(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("users", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetUsersResult> getUsers(InvokeArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("confluentcloud:index/getUsers:getUsers", TypeShape.of(GetUsersResult.class), args, Utilities.withVersion(options));
    }
    /**
     * [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy)
     * 
     * `confluentcloud.getUsers` describes a data source for Users.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.confluentcloud.ConfluentcloudFunctions;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var main = ConfluentcloudFunctions.getUsers(%!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference);
     * 
     *         ctx.export("users", main.ids());
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetUsersResult> getUsersPlain(InvokeArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("confluentcloud:index/getUsers:getUsers", TypeShape.of(GetUsersResult.class), args, Utilities.withVersion(options));
    }
}
