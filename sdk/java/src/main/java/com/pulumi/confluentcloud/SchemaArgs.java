// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.confluentcloud;

import com.pulumi.confluentcloud.inputs.SchemaCredentialsArgs;
import com.pulumi.confluentcloud.inputs.SchemaSchemaReferenceArgs;
import com.pulumi.confluentcloud.inputs.SchemaSchemaRegistryClusterArgs;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import java.lang.Boolean;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class SchemaArgs extends com.pulumi.resources.ResourceArgs {

    public static final SchemaArgs Empty = new SchemaArgs();

    /**
     * The Cluster API Credentials.
     * 
     */
    @Import(name="credentials")
    private @Nullable Output<SchemaCredentialsArgs> credentials;

    /**
     * @return The Cluster API Credentials.
     * 
     */
    public Optional<Output<SchemaCredentialsArgs>> credentials() {
        return Optional.ofNullable(this.credentials);
    }

    /**
     * The format of the schema. Accepted values are: `AVRO`, `PROTOBUF`, and `JSON`.
     * 
     */
    @Import(name="format", required=true)
    private Output<String> format;

    /**
     * @return The format of the schema. Accepted values are: `AVRO`, `PROTOBUF`, and `JSON`.
     * 
     */
    public Output<String> format() {
        return this.format;
    }

    /**
     * An optional flag to control whether a schema should be soft or hard deleted. Set it to `true` if you want to hard delete a schema on destroy (see [Schema Deletion Guidelines](https://docs.confluent.io/platform/current/schema-registry/schema-deletion-guidelines.html#schema-deletion-guidelines) for more details). Must be unset when importing. Defaults to `false` (soft delete).
     * 
     */
    @Import(name="hardDelete")
    private @Nullable Output<Boolean> hardDelete;

    /**
     * @return An optional flag to control whether a schema should be soft or hard deleted. Set it to `true` if you want to hard delete a schema on destroy (see [Schema Deletion Guidelines](https://docs.confluent.io/platform/current/schema-registry/schema-deletion-guidelines.html#schema-deletion-guidelines) for more details). Must be unset when importing. Defaults to `false` (soft delete).
     * 
     */
    public Optional<Output<Boolean>> hardDelete() {
        return Optional.ofNullable(this.hardDelete);
    }

    /**
     * An optional flag to control whether a schema should be recreated on an update. Set it to `true` if you want to manage different schema versions using different resource instances. Must be set to the target value when importing. Defaults to `false`, which manages the latest schema version only. The resource instance always points to the latest schema version by supporting in-place updates.
     * 
     */
    @Import(name="recreateOnUpdate")
    private @Nullable Output<Boolean> recreateOnUpdate;

    /**
     * @return An optional flag to control whether a schema should be recreated on an update. Set it to `true` if you want to manage different schema versions using different resource instances. Must be set to the target value when importing. Defaults to `false`, which manages the latest schema version only. The resource instance always points to the latest schema version by supporting in-place updates.
     * 
     */
    public Optional<Output<Boolean>> recreateOnUpdate() {
        return Optional.ofNullable(this.recreateOnUpdate);
    }

    /**
     * The REST endpoint of the Schema Registry cluster, for example, `https://psrc-00000.us-central1.gcp.confluent.cloud:443`).
     * 
     */
    @Import(name="restEndpoint")
    private @Nullable Output<String> restEndpoint;

    /**
     * @return The REST endpoint of the Schema Registry cluster, for example, `https://psrc-00000.us-central1.gcp.confluent.cloud:443`).
     * 
     */
    public Optional<Output<String>> restEndpoint() {
        return Optional.ofNullable(this.restEndpoint);
    }

    /**
     * The schema string, for example, `file(&#34;./schema_version_1.avsc&#34;)`.
     * 
     */
    @Import(name="schema")
    private @Nullable Output<String> schema;

    /**
     * @return The schema string, for example, `file(&#34;./schema_version_1.avsc&#34;)`.
     * 
     */
    public Optional<Output<String>> schema() {
        return Optional.ofNullable(this.schema);
    }

    /**
     * The list of referenced schemas (see [Schema References](https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#schema-references) for more details):
     * 
     */
    @Import(name="schemaReferences")
    private @Nullable Output<List<SchemaSchemaReferenceArgs>> schemaReferences;

    /**
     * @return The list of referenced schemas (see [Schema References](https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#schema-references) for more details):
     * 
     */
    public Optional<Output<List<SchemaSchemaReferenceArgs>>> schemaReferences() {
        return Optional.ofNullable(this.schemaReferences);
    }

    @Import(name="schemaRegistryCluster")
    private @Nullable Output<SchemaSchemaRegistryClusterArgs> schemaRegistryCluster;

    public Optional<Output<SchemaSchemaRegistryClusterArgs>> schemaRegistryCluster() {
        return Optional.ofNullable(this.schemaRegistryCluster);
    }

    /**
     * The name for the reference. (For Avro Schema, the reference name is the fully qualified schema name, for JSON Schema it is a URL, and for Protobuf Schema, it is the name of another Protobuf file.)
     * 
     */
    @Import(name="subjectName", required=true)
    private Output<String> subjectName;

    /**
     * @return The name for the reference. (For Avro Schema, the reference name is the fully qualified schema name, for JSON Schema it is a URL, and for Protobuf Schema, it is the name of another Protobuf file.)
     * 
     */
    public Output<String> subjectName() {
        return this.subjectName;
    }

    private SchemaArgs() {}

    private SchemaArgs(SchemaArgs $) {
        this.credentials = $.credentials;
        this.format = $.format;
        this.hardDelete = $.hardDelete;
        this.recreateOnUpdate = $.recreateOnUpdate;
        this.restEndpoint = $.restEndpoint;
        this.schema = $.schema;
        this.schemaReferences = $.schemaReferences;
        this.schemaRegistryCluster = $.schemaRegistryCluster;
        this.subjectName = $.subjectName;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(SchemaArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private SchemaArgs $;

        public Builder() {
            $ = new SchemaArgs();
        }

        public Builder(SchemaArgs defaults) {
            $ = new SchemaArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param credentials The Cluster API Credentials.
         * 
         * @return builder
         * 
         */
        public Builder credentials(@Nullable Output<SchemaCredentialsArgs> credentials) {
            $.credentials = credentials;
            return this;
        }

        /**
         * @param credentials The Cluster API Credentials.
         * 
         * @return builder
         * 
         */
        public Builder credentials(SchemaCredentialsArgs credentials) {
            return credentials(Output.of(credentials));
        }

        /**
         * @param format The format of the schema. Accepted values are: `AVRO`, `PROTOBUF`, and `JSON`.
         * 
         * @return builder
         * 
         */
        public Builder format(Output<String> format) {
            $.format = format;
            return this;
        }

        /**
         * @param format The format of the schema. Accepted values are: `AVRO`, `PROTOBUF`, and `JSON`.
         * 
         * @return builder
         * 
         */
        public Builder format(String format) {
            return format(Output.of(format));
        }

        /**
         * @param hardDelete An optional flag to control whether a schema should be soft or hard deleted. Set it to `true` if you want to hard delete a schema on destroy (see [Schema Deletion Guidelines](https://docs.confluent.io/platform/current/schema-registry/schema-deletion-guidelines.html#schema-deletion-guidelines) for more details). Must be unset when importing. Defaults to `false` (soft delete).
         * 
         * @return builder
         * 
         */
        public Builder hardDelete(@Nullable Output<Boolean> hardDelete) {
            $.hardDelete = hardDelete;
            return this;
        }

        /**
         * @param hardDelete An optional flag to control whether a schema should be soft or hard deleted. Set it to `true` if you want to hard delete a schema on destroy (see [Schema Deletion Guidelines](https://docs.confluent.io/platform/current/schema-registry/schema-deletion-guidelines.html#schema-deletion-guidelines) for more details). Must be unset when importing. Defaults to `false` (soft delete).
         * 
         * @return builder
         * 
         */
        public Builder hardDelete(Boolean hardDelete) {
            return hardDelete(Output.of(hardDelete));
        }

        /**
         * @param recreateOnUpdate An optional flag to control whether a schema should be recreated on an update. Set it to `true` if you want to manage different schema versions using different resource instances. Must be set to the target value when importing. Defaults to `false`, which manages the latest schema version only. The resource instance always points to the latest schema version by supporting in-place updates.
         * 
         * @return builder
         * 
         */
        public Builder recreateOnUpdate(@Nullable Output<Boolean> recreateOnUpdate) {
            $.recreateOnUpdate = recreateOnUpdate;
            return this;
        }

        /**
         * @param recreateOnUpdate An optional flag to control whether a schema should be recreated on an update. Set it to `true` if you want to manage different schema versions using different resource instances. Must be set to the target value when importing. Defaults to `false`, which manages the latest schema version only. The resource instance always points to the latest schema version by supporting in-place updates.
         * 
         * @return builder
         * 
         */
        public Builder recreateOnUpdate(Boolean recreateOnUpdate) {
            return recreateOnUpdate(Output.of(recreateOnUpdate));
        }

        /**
         * @param restEndpoint The REST endpoint of the Schema Registry cluster, for example, `https://psrc-00000.us-central1.gcp.confluent.cloud:443`).
         * 
         * @return builder
         * 
         */
        public Builder restEndpoint(@Nullable Output<String> restEndpoint) {
            $.restEndpoint = restEndpoint;
            return this;
        }

        /**
         * @param restEndpoint The REST endpoint of the Schema Registry cluster, for example, `https://psrc-00000.us-central1.gcp.confluent.cloud:443`).
         * 
         * @return builder
         * 
         */
        public Builder restEndpoint(String restEndpoint) {
            return restEndpoint(Output.of(restEndpoint));
        }

        /**
         * @param schema The schema string, for example, `file(&#34;./schema_version_1.avsc&#34;)`.
         * 
         * @return builder
         * 
         */
        public Builder schema(@Nullable Output<String> schema) {
            $.schema = schema;
            return this;
        }

        /**
         * @param schema The schema string, for example, `file(&#34;./schema_version_1.avsc&#34;)`.
         * 
         * @return builder
         * 
         */
        public Builder schema(String schema) {
            return schema(Output.of(schema));
        }

        /**
         * @param schemaReferences The list of referenced schemas (see [Schema References](https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#schema-references) for more details):
         * 
         * @return builder
         * 
         */
        public Builder schemaReferences(@Nullable Output<List<SchemaSchemaReferenceArgs>> schemaReferences) {
            $.schemaReferences = schemaReferences;
            return this;
        }

        /**
         * @param schemaReferences The list of referenced schemas (see [Schema References](https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#schema-references) for more details):
         * 
         * @return builder
         * 
         */
        public Builder schemaReferences(List<SchemaSchemaReferenceArgs> schemaReferences) {
            return schemaReferences(Output.of(schemaReferences));
        }

        /**
         * @param schemaReferences The list of referenced schemas (see [Schema References](https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#schema-references) for more details):
         * 
         * @return builder
         * 
         */
        public Builder schemaReferences(SchemaSchemaReferenceArgs... schemaReferences) {
            return schemaReferences(List.of(schemaReferences));
        }

        public Builder schemaRegistryCluster(@Nullable Output<SchemaSchemaRegistryClusterArgs> schemaRegistryCluster) {
            $.schemaRegistryCluster = schemaRegistryCluster;
            return this;
        }

        public Builder schemaRegistryCluster(SchemaSchemaRegistryClusterArgs schemaRegistryCluster) {
            return schemaRegistryCluster(Output.of(schemaRegistryCluster));
        }

        /**
         * @param subjectName The name for the reference. (For Avro Schema, the reference name is the fully qualified schema name, for JSON Schema it is a URL, and for Protobuf Schema, it is the name of another Protobuf file.)
         * 
         * @return builder
         * 
         */
        public Builder subjectName(Output<String> subjectName) {
            $.subjectName = subjectName;
            return this;
        }

        /**
         * @param subjectName The name for the reference. (For Avro Schema, the reference name is the fully qualified schema name, for JSON Schema it is a URL, and for Protobuf Schema, it is the name of another Protobuf file.)
         * 
         * @return builder
         * 
         */
        public Builder subjectName(String subjectName) {
            return subjectName(Output.of(subjectName));
        }

        public SchemaArgs build() {
            $.format = Objects.requireNonNull($.format, "expected parameter 'format' to be non-null");
            $.subjectName = Objects.requireNonNull($.subjectName, "expected parameter 'subjectName' to be non-null");
            return $;
        }
    }

}
