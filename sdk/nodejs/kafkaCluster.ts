// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "./types/input";
import * as outputs from "./types/output";
import * as utilities from "./utilities";

/**
 * ## Example Usage
 *
 * ### Example Kafka clusters on AWS
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as confluentcloud from "@pulumi/confluentcloud";
 *
 * const development = new confluentcloud.Environment("development", {displayName: "Development"});
 * const basic = new confluentcloud.KafkaCluster("basic", {
 *     displayName: "basic_kafka_cluster",
 *     availability: "SINGLE_ZONE",
 *     cloud: "AWS",
 *     region: "us-east-2",
 *     basic: {},
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * const standard = new confluentcloud.KafkaCluster("standard", {
 *     displayName: "standard_kafka_cluster",
 *     availability: "SINGLE_ZONE",
 *     cloud: "AWS",
 *     region: "us-east-2",
 *     standard: {},
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * const enterprise = new confluentcloud.KafkaCluster("enterprise", {
 *     enterprises: [{}],
 *     displayName: "enterprise_kafka_cluster",
 *     availability: "HIGH",
 *     cloud: "AWS",
 *     region: "us-east-2",
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * const dedicated = new confluentcloud.KafkaCluster("dedicated", {
 *     displayName: "dedicated_kafka_cluster",
 *     availability: "MULTI_ZONE",
 *     cloud: "AWS",
 *     region: "us-east-2",
 *     dedicated: {
 *         cku: 2,
 *     },
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * const freight = new confluentcloud.KafkaCluster("freight", {
 *     freights: [{}],
 *     displayName: "freight_kafka_cluster",
 *     availability: "HIGH",
 *     cloud: "AWS",
 *     region: "us-east-1",
 *     environment: {
 *         id: staging.id,
 *     },
 * });
 * ```
 *
 * ### Example Kafka clusters on Azure
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as confluentcloud from "@pulumi/confluentcloud";
 *
 * const development = new confluentcloud.Environment("development", {displayName: "Development"});
 * const basic = new confluentcloud.KafkaCluster("basic", {
 *     displayName: "basic_kafka_cluster",
 *     availability: "SINGLE_ZONE",
 *     cloud: "AZURE",
 *     region: "centralus",
 *     basic: {},
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * const standard = new confluentcloud.KafkaCluster("standard", {
 *     displayName: "standard_kafka_cluster",
 *     availability: "SINGLE_ZONE",
 *     cloud: "AZURE",
 *     region: "centralus",
 *     standard: {},
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * const enterprise = new confluentcloud.KafkaCluster("enterprise", {
 *     enterprises: [{}],
 *     displayName: "enterprise_kafka_cluster",
 *     availability: "HIGH",
 *     cloud: "AZURE",
 *     region: "centralus",
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * const dedicated = new confluentcloud.KafkaCluster("dedicated", {
 *     displayName: "dedicated_kafka_cluster",
 *     availability: "MULTI_ZONE",
 *     cloud: "AZURE",
 *     region: "centralus",
 *     dedicated: {
 *         cku: 2,
 *     },
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * ```
 *
 * ### Example Kafka clusters on GCP
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as confluentcloud from "@pulumi/confluentcloud";
 *
 * const development = new confluentcloud.Environment("development", {displayName: "Development"});
 * const basic = new confluentcloud.KafkaCluster("basic", {
 *     displayName: "basic_kafka_cluster",
 *     availability: "SINGLE_ZONE",
 *     cloud: "GCP",
 *     region: "us-central1",
 *     basic: {},
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * const standard = new confluentcloud.KafkaCluster("standard", {
 *     displayName: "standard_kafka_cluster",
 *     availability: "SINGLE_ZONE",
 *     cloud: "GCP",
 *     region: "us-central1",
 *     standard: {},
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * const dedicated = new confluentcloud.KafkaCluster("dedicated", {
 *     displayName: "dedicated_kafka_cluster",
 *     availability: "MULTI_ZONE",
 *     cloud: "GCP",
 *     region: "us-central1",
 *     dedicated: {
 *         cku: 2,
 *     },
 *     environment: {
 *         id: development.id,
 *     },
 * });
 * ```
 *
 * ## Getting Started
 *
 * The following end-to-end examples might help to get started with `confluentcloud.KafkaCluster` resource:
 *   * basic-kafka-acls: _Basic_ Kafka cluster with authorization using ACLs
 *   * basic-kafka-acls-with-alias: _Basic_ Kafka cluster with authorization using ACLs
 *   * standard-kafka-acls: _Standard_ Kafka cluster with authorization using ACLs
 *   * standard-kafka-rbac: _Standard_ Kafka cluster with authorization using RBAC
 *   * dedicated-public-kafka-acls: _Dedicated_ Kafka cluster that is accessible over the public internet with authorization using ACLs
 *   * dedicated-public-kafka-rbac: _Dedicated_ Kafka cluster that is accessible over the public internet with authorization using RBAC
 *   * dedicated-privatelink-aws-kafka-acls: _Dedicated_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
 *   * dedicated-privatelink-aws-kafka-rbac: _Dedicated_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using RBAC
 *   * dedicated-privatelink-azure-kafka-rbac: _Dedicated_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using RBAC
 *   * dedicated-privatelink-azure-kafka-acls: _Dedicated_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
 *   * dedicated-private-service-connect-gcp-kafka-acls: _Dedicated_ Kafka cluster on GCP that is accessible via Private Service Connect connections with authorization using ACLs
 *   * dedicated-private-service-connect-gcp-kafka-rbac: _Dedicated_ Kafka cluster on GCP that is accessible via Private Service Connect connections with authorization using RBAC
 *   * dedicated-vnet-peering-azure-kafka-acls: _Dedicated_ Kafka cluster on Azure that is accessible via VPC Peering connections with authorization using ACLs
 *   * dedicated-vnet-peering-azure-kafka-rbac: _Dedicated_ Kafka cluster on Azure that is accessible via VPC Peering connections with authorization using RBAC
 *   * dedicated-vpc-peering-aws-kafka-acls: _Dedicated_ Kafka cluster on AWS that is accessible via VPC Peering connections with authorization using ACLs
 *   * dedicated-vpc-peering-aws-kafka-rbac: _Dedicated_ Kafka cluster on AWS that is accessible via VPC Peering connections with authorization using RBAC
 *   * dedicated-vpc-peering-gcp-kafka-acls: _Dedicated_ Kafka cluster on GCP that is accessible via VPC Peering connections with authorization using ACLs
 *   * dedicated-vpc-peering-gcp-kafka-rbac: _Dedicated_ Kafka cluster on GCP that is accessible via VPC Peering connections with authorization using RBAC
 *   * dedicated-transit-gateway-attachment-aws-kafka-acls: _Dedicated_ Kafka cluster on AWS that is accessible via Transit Gateway Endpoint with authorization using ACLs
 *   * dedicated-transit-gateway-attachment-aws-kafka-rbac: _Dedicated_ Kafka cluster on AWS that is accessible via Transit Gateway Endpoint with authorization using RBAC
 *   * enterprise-privatelinkattachment-aws-kafka-acls: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs
 *   * enterprise-privatelinkattachment-azure-kafka-acls: _Enterprise_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs
 *   * enterprise-pni-aws-kafka-rbac: _Enterprise_ Kafka cluster on AWS that is accessible via Confluent Private Network Interface (PNI) with authorization using RBAC
 *   * freight-aws-kafka-rbac: _Freight_ Kafka cluster on AWS that is accessible via Confluent Private Network Interface (PNI) with authorization using RBAC
 *
 * ## Import
 *
 * You can import a Kafka cluster by using Environment ID and Kafka cluster ID, in the format `<Environment ID>/<Kafka cluster ID>`, e.g.
 *
 * $ export CONFLUENT_CLOUD_API_KEY="<cloud_api_key>"
 *
 * $ export CONFLUENT_CLOUD_API_SECRET="<cloud_api_secret>"
 *
 * ```sh
 * $ pulumi import confluentcloud:index/kafkaCluster:KafkaCluster my_kafka env-abc123/lkc-abc123
 * ```
 *
 * !> **Warning:** Do not forget to delete terminal command history afterwards for security purposes.
 */
export class KafkaCluster extends pulumi.CustomResource {
    /**
     * Get an existing KafkaCluster resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: KafkaClusterState, opts?: pulumi.CustomResourceOptions): KafkaCluster {
        return new KafkaCluster(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'confluentcloud:index/kafkaCluster:KafkaCluster';

    /**
     * Returns true if the given object is an instance of KafkaCluster.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is KafkaCluster {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === KafkaCluster.__pulumiType;
    }

    /**
     * (Required String) An API Version of the schema version of the Kafka cluster, for example, `cmk/v2`.
     */
    declare public /*out*/ readonly apiVersion: pulumi.Output<string>;
    /**
     * The availability zone configuration of the Kafka cluster. Accepted values are: `SINGLE_ZONE`, `MULTI_ZONE`, `LOW`, and `HIGH`.
     */
    declare public readonly availability: pulumi.Output<string>;
    /**
     * The configuration of the Basic Kafka cluster.
     */
    declare public readonly basic: pulumi.Output<outputs.KafkaClusterBasic | undefined>;
    /**
     * (Required String) The bootstrap endpoint used by Kafka clients to connect to the cluster (for example, `lkc-abc123-apfoo123.eu-west-3.aws.accesspoint.glb.confluent.cloud:9092`).
     */
    declare public /*out*/ readonly bootstrapEndpoint: pulumi.Output<string>;
    declare public readonly byokKey: pulumi.Output<outputs.KafkaClusterByokKey>;
    /**
     * The cloud service provider that runs the Kafka cluster. Accepted values are: `AWS`, `AZURE`, and `GCP`.
     */
    declare public readonly cloud: pulumi.Output<string>;
    /**
     * (Optional Configuration Block) The configuration of the Dedicated Kafka cluster. It supports the following:
     */
    declare public readonly dedicated: pulumi.Output<outputs.KafkaClusterDedicated | undefined>;
    /**
     * The name of the Kafka cluster.
     */
    declare public readonly displayName: pulumi.Output<string>;
    /**
     * (Optional List) The list of endpoints for connecting to the Kafka cluster. These endpoints provide different network access methods or regions for connecting to the cluster:
     */
    declare public /*out*/ readonly endpoints: pulumi.Output<outputs.KafkaClusterEndpoint[]>;
    /**
     * The configuration of the Enterprise Kafka cluster.
     */
    declare public readonly enterprises: pulumi.Output<outputs.KafkaClusterEnterprise[] | undefined>;
    /**
     * Environment objects represent an isolated namespace for your Confluent resources for organizational purposes.
     */
    declare public readonly environment: pulumi.Output<outputs.KafkaClusterEnvironment>;
    /**
     * The configuration of the Freight Kafka cluster.
     */
    declare public readonly freights: pulumi.Output<outputs.KafkaClusterFreight[] | undefined>;
    /**
     * (Required String) A kind of the Kafka cluster, for example, `Cluster`.
     */
    declare public /*out*/ readonly kind: pulumi.Output<string>;
    /**
     * Network represents a network (VPC) in Confluent Cloud. All Networks exist within Confluent-managed cloud provider accounts.
     */
    declare public readonly network: pulumi.Output<outputs.KafkaClusterNetwork>;
    /**
     * (Required String) The Confluent Resource Name (CRN) of the Kafka cluster, for example, `crn://confluent.cloud/organization=1111aaaa-11aa-11aa-11aa-111111aaaaaa/environment=env-abc123/cloud-cluster=lkc-abc123`. Some resources, like topics, require appending the Kafka cluster ID for creating role bindings, for example, `/kafka=lkc-123abc`. For more information, see confluentcloud.RoleBinding Resource.
     */
    declare public /*out*/ readonly rbacCrn: pulumi.Output<string>;
    /**
     * The cloud service provider region where the Kafka cluster is running, for example, `us-west-2`. See [Cloud Providers and Regions](https://docs.confluent.io/cloud/current/clusters/regions.html#cloud-providers-and-regions) for a full list of options for AWS, Azure, and GCP.
     */
    declare public readonly region: pulumi.Output<string>;
    /**
     * (Required String) The REST endpoint of the Kafka cluster (for example, `https://lkc-abc123-apfoo123.eu-west-3.aws.accesspoint.glb.confluent.cloud:443`).
     */
    declare public /*out*/ readonly restEndpoint: pulumi.Output<string>;
    /**
     * The configuration of the Standard Kafka cluster.
     */
    declare public readonly standard: pulumi.Output<outputs.KafkaClusterStandard | undefined>;

    /**
     * Create a KafkaCluster resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: KafkaClusterArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: KafkaClusterArgs | KafkaClusterState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as KafkaClusterState | undefined;
            resourceInputs["apiVersion"] = state?.apiVersion;
            resourceInputs["availability"] = state?.availability;
            resourceInputs["basic"] = state?.basic;
            resourceInputs["bootstrapEndpoint"] = state?.bootstrapEndpoint;
            resourceInputs["byokKey"] = state?.byokKey;
            resourceInputs["cloud"] = state?.cloud;
            resourceInputs["dedicated"] = state?.dedicated;
            resourceInputs["displayName"] = state?.displayName;
            resourceInputs["endpoints"] = state?.endpoints;
            resourceInputs["enterprises"] = state?.enterprises;
            resourceInputs["environment"] = state?.environment;
            resourceInputs["freights"] = state?.freights;
            resourceInputs["kind"] = state?.kind;
            resourceInputs["network"] = state?.network;
            resourceInputs["rbacCrn"] = state?.rbacCrn;
            resourceInputs["region"] = state?.region;
            resourceInputs["restEndpoint"] = state?.restEndpoint;
            resourceInputs["standard"] = state?.standard;
        } else {
            const args = argsOrState as KafkaClusterArgs | undefined;
            if (args?.availability === undefined && !opts.urn) {
                throw new Error("Missing required property 'availability'");
            }
            if (args?.cloud === undefined && !opts.urn) {
                throw new Error("Missing required property 'cloud'");
            }
            if (args?.environment === undefined && !opts.urn) {
                throw new Error("Missing required property 'environment'");
            }
            if (args?.region === undefined && !opts.urn) {
                throw new Error("Missing required property 'region'");
            }
            resourceInputs["availability"] = args?.availability;
            resourceInputs["basic"] = args?.basic;
            resourceInputs["byokKey"] = args?.byokKey;
            resourceInputs["cloud"] = args?.cloud;
            resourceInputs["dedicated"] = args?.dedicated;
            resourceInputs["displayName"] = args?.displayName;
            resourceInputs["enterprises"] = args?.enterprises;
            resourceInputs["environment"] = args?.environment;
            resourceInputs["freights"] = args?.freights;
            resourceInputs["network"] = args?.network;
            resourceInputs["region"] = args?.region;
            resourceInputs["standard"] = args?.standard;
            resourceInputs["apiVersion"] = undefined /*out*/;
            resourceInputs["bootstrapEndpoint"] = undefined /*out*/;
            resourceInputs["endpoints"] = undefined /*out*/;
            resourceInputs["kind"] = undefined /*out*/;
            resourceInputs["rbacCrn"] = undefined /*out*/;
            resourceInputs["restEndpoint"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(KafkaCluster.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering KafkaCluster resources.
 */
export interface KafkaClusterState {
    /**
     * (Required String) An API Version of the schema version of the Kafka cluster, for example, `cmk/v2`.
     */
    apiVersion?: pulumi.Input<string>;
    /**
     * The availability zone configuration of the Kafka cluster. Accepted values are: `SINGLE_ZONE`, `MULTI_ZONE`, `LOW`, and `HIGH`.
     */
    availability?: pulumi.Input<string>;
    /**
     * The configuration of the Basic Kafka cluster.
     */
    basic?: pulumi.Input<inputs.KafkaClusterBasic>;
    /**
     * (Required String) The bootstrap endpoint used by Kafka clients to connect to the cluster (for example, `lkc-abc123-apfoo123.eu-west-3.aws.accesspoint.glb.confluent.cloud:9092`).
     */
    bootstrapEndpoint?: pulumi.Input<string>;
    byokKey?: pulumi.Input<inputs.KafkaClusterByokKey>;
    /**
     * The cloud service provider that runs the Kafka cluster. Accepted values are: `AWS`, `AZURE`, and `GCP`.
     */
    cloud?: pulumi.Input<string>;
    /**
     * (Optional Configuration Block) The configuration of the Dedicated Kafka cluster. It supports the following:
     */
    dedicated?: pulumi.Input<inputs.KafkaClusterDedicated>;
    /**
     * The name of the Kafka cluster.
     */
    displayName?: pulumi.Input<string>;
    /**
     * (Optional List) The list of endpoints for connecting to the Kafka cluster. These endpoints provide different network access methods or regions for connecting to the cluster:
     */
    endpoints?: pulumi.Input<pulumi.Input<inputs.KafkaClusterEndpoint>[]>;
    /**
     * The configuration of the Enterprise Kafka cluster.
     */
    enterprises?: pulumi.Input<pulumi.Input<inputs.KafkaClusterEnterprise>[]>;
    /**
     * Environment objects represent an isolated namespace for your Confluent resources for organizational purposes.
     */
    environment?: pulumi.Input<inputs.KafkaClusterEnvironment>;
    /**
     * The configuration of the Freight Kafka cluster.
     */
    freights?: pulumi.Input<pulumi.Input<inputs.KafkaClusterFreight>[]>;
    /**
     * (Required String) A kind of the Kafka cluster, for example, `Cluster`.
     */
    kind?: pulumi.Input<string>;
    /**
     * Network represents a network (VPC) in Confluent Cloud. All Networks exist within Confluent-managed cloud provider accounts.
     */
    network?: pulumi.Input<inputs.KafkaClusterNetwork>;
    /**
     * (Required String) The Confluent Resource Name (CRN) of the Kafka cluster, for example, `crn://confluent.cloud/organization=1111aaaa-11aa-11aa-11aa-111111aaaaaa/environment=env-abc123/cloud-cluster=lkc-abc123`. Some resources, like topics, require appending the Kafka cluster ID for creating role bindings, for example, `/kafka=lkc-123abc`. For more information, see confluentcloud.RoleBinding Resource.
     */
    rbacCrn?: pulumi.Input<string>;
    /**
     * The cloud service provider region where the Kafka cluster is running, for example, `us-west-2`. See [Cloud Providers and Regions](https://docs.confluent.io/cloud/current/clusters/regions.html#cloud-providers-and-regions) for a full list of options for AWS, Azure, and GCP.
     */
    region?: pulumi.Input<string>;
    /**
     * (Required String) The REST endpoint of the Kafka cluster (for example, `https://lkc-abc123-apfoo123.eu-west-3.aws.accesspoint.glb.confluent.cloud:443`).
     */
    restEndpoint?: pulumi.Input<string>;
    /**
     * The configuration of the Standard Kafka cluster.
     */
    standard?: pulumi.Input<inputs.KafkaClusterStandard>;
}

/**
 * The set of arguments for constructing a KafkaCluster resource.
 */
export interface KafkaClusterArgs {
    /**
     * The availability zone configuration of the Kafka cluster. Accepted values are: `SINGLE_ZONE`, `MULTI_ZONE`, `LOW`, and `HIGH`.
     */
    availability: pulumi.Input<string>;
    /**
     * The configuration of the Basic Kafka cluster.
     */
    basic?: pulumi.Input<inputs.KafkaClusterBasic>;
    byokKey?: pulumi.Input<inputs.KafkaClusterByokKey>;
    /**
     * The cloud service provider that runs the Kafka cluster. Accepted values are: `AWS`, `AZURE`, and `GCP`.
     */
    cloud: pulumi.Input<string>;
    /**
     * (Optional Configuration Block) The configuration of the Dedicated Kafka cluster. It supports the following:
     */
    dedicated?: pulumi.Input<inputs.KafkaClusterDedicated>;
    /**
     * The name of the Kafka cluster.
     */
    displayName?: pulumi.Input<string>;
    /**
     * The configuration of the Enterprise Kafka cluster.
     */
    enterprises?: pulumi.Input<pulumi.Input<inputs.KafkaClusterEnterprise>[]>;
    /**
     * Environment objects represent an isolated namespace for your Confluent resources for organizational purposes.
     */
    environment: pulumi.Input<inputs.KafkaClusterEnvironment>;
    /**
     * The configuration of the Freight Kafka cluster.
     */
    freights?: pulumi.Input<pulumi.Input<inputs.KafkaClusterFreight>[]>;
    /**
     * Network represents a network (VPC) in Confluent Cloud. All Networks exist within Confluent-managed cloud provider accounts.
     */
    network?: pulumi.Input<inputs.KafkaClusterNetwork>;
    /**
     * The cloud service provider region where the Kafka cluster is running, for example, `us-west-2`. See [Cloud Providers and Regions](https://docs.confluent.io/cloud/current/clusters/regions.html#cloud-providers-and-regions) for a full list of options for AWS, Azure, and GCP.
     */
    region: pulumi.Input<string>;
    /**
     * The configuration of the Standard Kafka cluster.
     */
    standard?: pulumi.Input<inputs.KafkaClusterStandard>;
}
